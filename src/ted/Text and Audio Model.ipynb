{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "import glob, os, sys,re,json\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import sys,json,gzip,random,re,math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import linear_model\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "from tensorflow.python.ops.rnn import dynamic_rnn\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Load in files from the Liu et al. 2017 dataset and read vocab </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2483"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_liu_transcript_paths():\n",
    "    pathname=\"/data/corpora/ted/transcripts_clean/\"\n",
    "    files = [pathname + f for f in os.listdir(pathname)]\n",
    "    talk_names_path = \"talk_names.txt\"\n",
    "    talk_names = open(talk_names_path).read().replace('.txt','.html').split('\\n')\n",
    "    talk_names = ['isabel_allende_how_to_live_passionately_no_matter_your_age.html' if t == 'isabelle_allende_how_to_live_passionately_no_matter_your_age.html' else t for t in talk_names]\n",
    "    talk_names = [t for t in talk_names if t not in ['', 'test.html', '\\r']]\n",
    "    transcripts = [pathname + t for t in talk_names]\n",
    "    return(transcripts)\n",
    "\n",
    "#transcripts = get_liu_transcript_paths()\n",
    "#len(transcripts)\n",
    "\n",
    "def get_transcript_paths():\n",
    "    pathname=\"/data/corpora/ted/transcripts_clean/\"\n",
    "    files = [pathname + f for f in os.listdir(pathname)]\n",
    "    return files\n",
    "\n",
    "transcripts = get_transcript_paths()\n",
    "len(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_transcript_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLIWC(filename):\n",
    "    liwc_vocab={}\n",
    "    regex_liwc={}\n",
    "    liwc={}\n",
    "    \n",
    "    # Liu excludes \"affective or emotional processes\"\n",
    "    invalid={}\n",
    "    invalid[\"31\"]=1\n",
    "    invalid[\"32\"]=1\n",
    "    invalid[\"33\"]=1\n",
    "    invalid[\"34\"]=1\n",
    "    invalid[\"35\"]=1\n",
    "\n",
    "    file=open(filename)\n",
    "    for i in range(75):\n",
    "        line=file.readline()\n",
    "        cols=re.split(\"\\s+\", line.rstrip())\n",
    "        if line.rstrip() != \"%\":\n",
    "            idd=\"%s\" % cols[0]\n",
    "            label=cols[1]\n",
    "            liwc_vocab[idd]=label\n",
    "    for line in file:\n",
    "        cols=line.rstrip().split(\"\\t\")\n",
    "        term=cols[0]\n",
    "        valid=[]\n",
    "        for x in cols[1:]:\n",
    "            if x not in invalid:\n",
    "                valid.append(x)\n",
    "        cats=[\"LIWC_%s\" % liwc_vocab[x] for x in valid]\n",
    "\n",
    "        if term.endswith(\"*\"):\n",
    "            pref=term[0:2]\n",
    "            if pref not in regex_liwc:\n",
    "                regex_liwc[pref]={}\n",
    "            regex_liwc[pref][term]=cats\n",
    "        else:\n",
    "            liwc[term]=cats\n",
    "            \n",
    "    return (liwc_vocab, regex_liwc, liwc)\n",
    "\n",
    "# get all flat LIWC categories for a word\n",
    "def getLIWC(word):\n",
    "    vals=[]\n",
    "    if word in liwc:\n",
    "        vals.extend(liwc[word])\n",
    "    if len(word) > 1:\n",
    "        pref=word[0:2]\n",
    "        if pref in regex_liwc:\n",
    "            cands=regex_liwc[pref]\n",
    "            for cand in cands:\n",
    "                if re.match(cand, word) != None:\n",
    "                    vals.extend(regex_liwc[pref][cand])\n",
    "    return vals\n",
    "\n",
    "def get_words(transcript_path):\n",
    "    words = []\n",
    "    text = open(transcript_path).read()\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [l for l in lines if l != '']\n",
    "    paragraphs = [line.split(\"\\t\")[1] for line in lines]\n",
    "    paragraphs = [p.replace(\"(Laughter)\",\"\").replace(\"(Applause)\",\"\") for p in paragraphs]\n",
    "    for p in paragraphs:\n",
    "        words += p.split(' ')\n",
    "    return words\n",
    "    \n",
    "\n",
    "def get_vocab(transcript_path_list):\n",
    "    vocab = {}\n",
    "    \n",
    "    words = []\n",
    "    for t in transcript_path_list:\n",
    "        words += get_words(t)\n",
    "        #words += t.get_words()\n",
    "        \n",
    "    fid = 1\n",
    "    \n",
    "    for key in liwc_vocab:\n",
    "        feat=\"LIWC_%s\" % (liwc_vocab[key])\n",
    "        vocab[feat]=fid\n",
    "        fid+=1\n",
    "        \n",
    "    counts=Counter()\n",
    "    \n",
    "    for word in words:\n",
    "        counts[word.lower()]+=1\n",
    "    \n",
    "    for word in counts:\n",
    "        count=counts[word]\n",
    "        #if count >= 500:\n",
    "        if count >= 500000:\n",
    "            vocab[word.lower()]=fid\n",
    "            fid+=1\n",
    "            \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "liwc_path = '/data/corpora/LIWC/LIWC.txt'\n",
    "liwc_vocab, regex_liwc, liwc = readLIWC(liwc_path)\n",
    "vocab = get_vocab(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/data/corpora/ted/transcripts_clean/linus_torvalds_the_mind_behind_linux.html'"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_transcript_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alignments_dir = '/data/corpora/ted/forced_alignments/'\n",
    "alignments_files = os.listdir(alignments_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matched = []\n",
    "for t in transcripts:\n",
    "    matcher = t.split(\"/\")[-1].replace(\".html\", \".json\")\n",
    "    if matcher in alignments_files:\n",
    "        matched.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cstm(s):\n",
    "    n_mins = int(s) / 60\n",
    "    n_secs = s - 60*n_mins\n",
    "    return (\"%i:%02.1f\") % (n_mins, n_secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pkl_path(filename):\n",
    "    return '/data/jrgillick/applause/transcripts/' + filename.split('transcripts_clean/')[1].split('.html')[0] + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/data/jrgillick/applause/transcripts/abigail_washburn_building_us_china_relations_by_banjo.pkl'"
      ]
     },
     "execution_count": 1317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pkl_path(t.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for transcript in matched[0:100]:\n",
    "    pkl_path = get_pkl_path(transcript)\n",
    "    if not os.path.exists(pkl_path):\n",
    "        t = Transcript(transcript)\n",
    "        t.compute_sentence_audio_features()    \n",
    "        with open(pkl_path,'wb') as f:\n",
    "            pickle.dump(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "t.compute_sentence_audio_features()\n",
    "time_elapsed = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.1519889831543"
      ]
     },
     "execution_count": 1288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.057394475,\n",
       " 0.0018195921,\n",
       " 0.12844008,\n",
       " 0.12662049,\n",
       " 0.032966193,\n",
       " 3.1899773242630385,\n",
       " 3.1348185217304767,\n",
       " 33.251755,\n",
       " 105.0,\n",
       " -1.0,\n",
       " 106.0,\n",
       " 37.384201,\n",
       " 0.5023622047244094]"
      ]
     },
     "execution_count": 1294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sentence_audio_features[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Most  of  us  think  of  motion  as  a  very  visual  thing . '"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sentences[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'AD :  And  there  are  other  ways  that  we  can  push  these  limits  as  well . ',\n",
       " (u'9:14.5', u'9:25.1'))"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=59\n",
    "zip([s[0] for s in t.sentences], [(cstm(at[0]),cstm(at[1])) for at in t.get_alignment_times()])[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(48, u'Little  lamb !'),\n",
       " (58,\n",
       "  u'( Audio )  Mary  had  a  little  lamb  whose  fleece  was  white  as  snow ,  and  everywhere  that  Mary  went ,  that  lamb  was  sure  to  go .'),\n",
       " (86,\n",
       "  u\"And  so  what  you  see  here  is  a  simulation  of  how  this  object  would  respond  to  new  forces  that  we 've  never  seen  before ,  and  we  created  it  from  just  five  seconds  of  regular  video .\"),\n",
       " (90,\n",
       "  u\"So  for  example ,  here 's  a  video  that  I  captured  of  a  bush  outside  of  my  apartment ,  and  I  did n't  do  anything  to  this  bush ,  but  by  capturing  a  minute - long  video ,  a  gentle  breeze  caused  enough  vibrations  that  we  could  learn  enough  about  this  bush  to  create  this  simulation . \"),\n",
       " (94,\n",
       "  u'So  here  are  the  amazing  people  who  worked  with  me  on  these  projects . ')]"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,s[0]) for i, s in enumerate(t.sentences) if s[2] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_transcripts = [t for t in all_transcripts if t.filename in matched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866"
      ]
     },
     "execution_count": 1083,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.389999, 16.759999999999998)"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_alignment_times()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/data/corpora/ted/transcripts_clean/abigail_washburn_building_us_china_relations_by_banjo.html'"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyAudioAnalysis\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import audioFeatureExtraction\n",
    "\n",
    "def get_pitch_tracking(audio, sr):\n",
    "    r = str(np.random.randint(999999))\n",
    "    librosa.output.write_wav('temp_%s.wav' % (r) ,audio,sr)\n",
    "    reaper_cmd = \"~/REAPER/build/reaper -i temp_%s.wav -f temp_%s.f0 -p temp_%s.pm -a\" % (r,r,r)\n",
    "    os.system(reaper_cmd)\n",
    "    txt = open('temp_%s.f0' %(r)).read()\n",
    "    txt = txt.split('\\n')[7:][0:-1]\n",
    "    split_lines = [l.split(' ') for l in txt]\n",
    "    cleanup_cmd = \"rm temp_%s.wav temp_%s.f0 temp_%s.pm\" %(r,r,r)\n",
    "    os.system(cleanup_cmd)\n",
    "    return split_lines\n",
    "\n",
    "def compute_audio_energy_features(audio):\n",
    "    rmse = librosa.feature.rmse(audio,frame_length=1024)\n",
    "    mean_energy = np.mean(rmse)\n",
    "    min_energy = np.min(rmse)\n",
    "    max_energy = np.max(rmse)\n",
    "    range_energy = max_energy - min_energy\n",
    "    std_energy = np.std(rmse)\n",
    "    return [mean_energy, min_energy, max_energy, range_energy, std_energy]\n",
    "\n",
    "def compute_audio_temporal_features(s,audio,sr):\n",
    "    duration = len(audio) / float(sr)\n",
    "    tempo = len(s) / duration\n",
    "    return [duration, tempo]\n",
    "    \n",
    "def compute_audio_pitch_features(audio,sr):\n",
    "    pitch_list = np.array([p[2] for p in get_pitch_tracking(audio,sr)]).astype(np.float32)\n",
    "    mean_pitch = np.mean(pitch_list)\n",
    "    max_pitch = np.max(pitch_list)\n",
    "    min_pitch = np.min(pitch_list)\n",
    "    range_pitch = max_pitch - min_pitch\n",
    "    std_pitch = np.std(pitch_list)\n",
    "    internal_silence = np.sum(pitch_list == -1) / float(len(pitch_list))\n",
    "    return [mean_pitch,max_pitch,min_pitch,range_pitch,std_pitch,internal_silence]\n",
    "    \n",
    "def compute_audio_features(s,audio,sr):\n",
    "    return compute_audio_energy_features(audio) + compute_audio_temporal_features(s,audio,sr) + compute_audio_pitch_features(audio,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create \"Transcript\" object to compute features from text files </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Transcript:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.sequences = self.get_sequences()\n",
    "        self.sentences = self.get_sentence_list()\n",
    "        self.full_text = self.get_sentence_text()\n",
    "        #self.alignment = self.get_alignments_file()\n",
    "        #self.alignment_times = self.get_alignment_times()\n",
    "        \n",
    "    def get_text(self):\n",
    "        return open(self.filename).read()\n",
    "    \n",
    "    def get_split_lines(self):\n",
    "        text = self.get_text()\n",
    "        lines = text.split(\"\\n\")\n",
    "        lines = [l for l in lines if l != '']\n",
    "        return [line.split(\"\\t\") for line in lines]\n",
    "    \n",
    "    def get_paragraphs(self):\n",
    "        split_lines = self.get_split_lines()\n",
    "        return [l[1] for l in split_lines]\n",
    "        \n",
    "    def get_timestamps(self):\n",
    "        split_lines = self.get_split_lines()\n",
    "        return [l[0] for l in split_lines]\n",
    "        \n",
    "    def get_sentences(self, paragraph):\n",
    "        #par = unicode(paragraph).encode(\"utf-8\")\n",
    "        paragraph = paragraph.replace('(Laughter)','')\n",
    "        sentences = []\n",
    "        doc = nlp(paragraph)\n",
    "        for sentence in doc.sents:\n",
    "            words=[]\n",
    "            for word in sentence:\n",
    "                if re.search(\"\\S\", word.string) != None:\n",
    "                    words.append(word.string)\n",
    "            text=' '.join(words)\n",
    "            if re.match(\"^\\(.*?\\)$\", text) != None or re.search(\"\\w\", text) == None:\n",
    "                continue\n",
    "            sentences.append(text)\n",
    "        return sentences\n",
    "    \n",
    "    def get_words(self):\n",
    "        words = []\n",
    "        paragraphs = [p.replace(\"(Laughter)\",\"\").replace(\"(Applause)\",\"\") for p in self.get_paragraphs()]\n",
    "        for p in paragraphs:\n",
    "            words += p.split(' ')\n",
    "        return words\n",
    "    \n",
    "    def get_sentences_with_applause_interspersed(self, paragraph):\n",
    "        paragraph = paragraph.replace('(Laughter)','')\n",
    "        lines = paragraph.split(\"(Applause)\")\n",
    "        last_line = lines[-1]; lines = lines[0:-1]  # Don't add applause after last line\n",
    "        sentences = []\n",
    "        for line in lines:\n",
    "            sentences += self.get_sentences(line)\n",
    "            sentences.append(\"(Applause)\")\n",
    "        sentences += self.get_sentences(last_line)\n",
    "        return sentences\n",
    "      \n",
    "    def get_sequences(self):\n",
    "        sequences = []\n",
    "        split_lines = self.get_split_lines()\n",
    "        for line in split_lines:\n",
    "            if \"(Applause)\" in line[1] and line[1] != \"(Applause)\":\n",
    "                timestamp = line[0]; paragraph = line[1]\n",
    "                sentences = self.get_sentences_with_applause_interspersed(paragraph)\n",
    "                sequences.append((timestamp, paragraph, sentences))\n",
    "                #special_cases.append(line[1])\n",
    "            elif line[1] == \"(Applause)\":\n",
    "                timestamp = line[0]; paragraph = line[1]; sentences = [\"(Applause)\"]\n",
    "                sequences.append((timestamp, paragraph, sentences))\n",
    "            else:\n",
    "                timestamp = line[0]; paragraph = line[1]; sentences = self.get_sentences(paragraph)\n",
    "                sequences.append((timestamp, paragraph, sentences))\n",
    "        return sequences\n",
    "    \n",
    "    def get_sentence_list(self):\n",
    "        all_sentences = []\n",
    "        seqs = self.sequences[0:-1] #exclude last paragraph, which may be final applause\n",
    "        for sequence_index, sequence in enumerate(seqs): \n",
    "            sentences = sequence[2]\n",
    "            for sentence_index, s in enumerate(sentences):\n",
    "                if s != \"(Applause)\":\n",
    "                    features = np.concatenate((self.get_dense_liwc_features(s),self.get_word_vec_features(s)))\n",
    "                    # If this is not the last sentence in the seq, check if next sentence in this sequence is applause\n",
    "                    if sentence_index < len(sentences)-1 and sentences[sentence_index+1] == \"(Applause)\":\n",
    "                        applause_follows = 1\n",
    "                    # If this is the last sentence of this sequence, check first sentence of next sequence\n",
    "                    elif sentence_index == len(sentences) -1 and sequence_index < len(seqs) - 1:\n",
    "                        next_sentences = seqs[sequence_index+1][2]\n",
    "                        if len(next_sentences) > 0 and next_sentences[0] == \"(Applause)\":\n",
    "                            applause_follows = 1\n",
    "                        else:\n",
    "                            applause_follows = 0    \n",
    "                    else:\n",
    "                        applause_follows = 0\n",
    "                    all_sentences.append((s,features,applause_follows))\n",
    "        return all_sentences\n",
    "    \n",
    "    def get_sentence_text(self):\n",
    "        return \" \".join([s[0].replace(\" \\'\",\"\\'\") for s in self.sentences])\n",
    "    \n",
    "    def get_indices_of_sentence_in_full_txt(self,s):\n",
    "        s = s.replace(\" \\'\",\"\\'\")\n",
    "        start = self.full_text.index(s)\n",
    "        end = start + len(s)\n",
    "        return (start, end)\n",
    "    \n",
    "    def get_last_detected_end_time(self, alignment, index):\n",
    "        while index >= 0:\n",
    "            if index < len(alignment['words']):\n",
    "                word = alignment['words'][index]\n",
    "                if 'end' in word.keys():\n",
    "                    return word['end']\n",
    "            index -= 1\n",
    "    \n",
    "    def get_last_detected_start_time(self, alignment, index):\n",
    "        if index >= len(alignment['words']):\n",
    "            index = len(alignment['words']) - 1\n",
    "        word = alignment['words'][index]\n",
    "        if 'start' in word.keys():\n",
    "            return word['start']\n",
    "        try:\n",
    "            next_word = alignment['words'][index+1]\n",
    "            if 'start' in next_word.keys():\n",
    "                return next_word['start'] - 0.1\n",
    "        except:\n",
    "            last_word = alignment['words'][index-1]\n",
    "            if 'start' in last_word.keys():\n",
    "                return last_word['end'] - 0.1\n",
    "        \n",
    "        while index >= 0:\n",
    "            word = alignment['words'][index]\n",
    "            if 'start' in word.keys():\n",
    "                return word['start']\n",
    "            index -= 1\n",
    "    \n",
    "    def get_sentence_words(self, s):\n",
    "        s = s.replace(\" \\'\",\"\\'\").replace(\"\\u2014\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"@\",\"\").replace(\"  \",\" \")\n",
    "        s_words = re.split(\"[, \\-!?:.&\\/\\\"]+\",s)\n",
    "        s_words = [s for s in s_words if re.search(\"\\w\", s) is not None]\n",
    "        s_words = [s[0:-1] if s[-1] in [\"\\'\",\"\\u2014\",\"%\"] else s for s in s_words ]\n",
    "        return s_words\n",
    "    \n",
    "    def get_alignment_times(self):\n",
    "        sentences = [s[0] for s in self.sentences]\n",
    "        alignment = self.alignment\n",
    "        alignment_index = 0\n",
    "        alignment_times = []\n",
    "        for idx, s in enumerate(sentences):\n",
    "            s_words = self.get_sentence_words(s)\n",
    "            alignment_words = alignment['words'][alignment_index:alignment_index+len(s_words)]\n",
    "            original_alignment_index = alignment_index\n",
    "            n_tries = 0; jump_amounts = [1,-1,2,-2,3]\n",
    "            if idx > 0 and idx < len(sentences) and len(s_words) > 0 and len(alignment_words) > 0:\n",
    "                while n_tries < 5 and s_words[0].lower() != alignment_words[0]['word'].lower():\n",
    "                    alignment_index = original_alignment_index + jump_amounts[n_tries]\n",
    "                    alignment_words = alignment['words'][alignment_index:alignment_index+len(s_words)]\n",
    "                    n_tries += 1\n",
    "            alignment_start = self.get_last_detected_start_time(alignment, alignment_index) #alignment['words'][alignment_index]['start']\n",
    "            alignment_end = self.get_last_detected_end_time(alignment, alignment_index + len(s_words) -1)#alignment['words'][alignment_index+len(s_words)]['end']\n",
    "            alignment_times.append((alignment_start,alignment_end))\n",
    "            alignment_index += len(s_words)\n",
    "        alignment_times = self.smooth_alignment_times(alignment_times)\n",
    "        return alignment_times\n",
    "    \n",
    "    def smooth_alignment_times(self, alignment_times):\n",
    "        for i in range(len(alignment_times)):\n",
    "            start, end = alignment_times[i]\n",
    "            if start is None and end is not None:\n",
    "                alignment_times[i] = (end-0.1, end)\n",
    "            if start is not None and end is None:\n",
    "                alignment_times[i] = (start, start+0.1)\n",
    "            if start is None and end is None:\n",
    "                counter = 1\n",
    "                next_start = None\n",
    "                while next_start is None:\n",
    "                    next_start = alignment_times[i+counter][0]\n",
    "                    counter+= 1\n",
    "                alignment_times[i] = (next_start-0.2, next_start-0.1)\n",
    "            if alignment_times[i][1] - alignment_times[i][0] < 0.1:\n",
    "                alignment_times[i] = (alignment_times[i][0], alignment_times[i][0]+0.1)\n",
    "        return alignment_times\n",
    "    \n",
    "    def get_sentence_audio_features(self):\n",
    "        audio_path = self.filename.replace(\"transcripts_clean\",\"audio\").replace(\".html\",\".mp3\")\n",
    "        y,sr = librosa.load(audio_path)\n",
    "        all_audio_features = []\n",
    "        for i in range(len(self.sentences)):\n",
    "            s = self.get_sentence_words(self.sentences[i][0])\n",
    "            start, end = self.alignment_times[i]\n",
    "            audio = y[int(sr*start):int(sr*end)]\n",
    "            audio_feats = compute_audio_features(s,audio,sr)\n",
    "            all_audio_features.append(audio_feats)\n",
    "        return all_audio_features\n",
    "    \n",
    "    def compute_sentence_audio_features(self):\n",
    "        self.sentence_audio_features = self.get_sentence_audio_features()          \n",
    "    \n",
    "    def get_word_vector_list(self, sentence):\n",
    "        vecs = []\n",
    "        for word in nlp(sentence):\n",
    "            if re.search(\"\\S\", word.string) != None: vecs.append(word.vector)\n",
    "        return np.array(vecs)\n",
    "    \n",
    "    def compute_word_features(self):\n",
    "        self.word_features = []\n",
    "        for index, sentence in enumerate(self.sentences):\n",
    "            s = sentence[0]\n",
    "            word_vecs = self.get_word_vector_list(s)\n",
    "            self.word_features.append(word_vecs)# self.sentences[index] = (sentence[0], sentence[1], sentence[2], word_vecs)\n",
    "    \n",
    "    def get_alignments_file(self):\n",
    "        sentences = [s[0].replace(\" '\",\"'\") for s in self.sentences]\n",
    "        alignment_file = self.filename.replace('transcripts_clean','forced_alignments').replace('.html','.json')\n",
    "        return json.loads(open(alignment_file).read())\n",
    "    \n",
    "    def get_words_in_sentence(self, sentence):\n",
    "        return [word for word in nlp(sentence) if re.search(\"\\S\", word.string) != None]\n",
    "\n",
    "    def count_words_in_sentence(self, sentence):\n",
    "        return len(self.get_words_in_sentence(sentence))\n",
    "    \n",
    "    def compute_word_count_list(self):\n",
    "        self.word_count_list = []\n",
    "        for sentence in self.sentences:\n",
    "            self.word_count_list.append(self.count_words_in_sentence(sentence[0]))\n",
    "            \n",
    "    def count_preceding_words(self, index):\n",
    "        return np.sum (self.word_count_list[0:index+1])\n",
    "    \n",
    "    def count_applause_instances(self):\n",
    "        c = 0\n",
    "        sentence_list = self.sentences\n",
    "        for s in sentence_list:#[0:-1]:\n",
    "            if s[2] == 1:\n",
    "                c += 1\n",
    "        return c\n",
    "    \n",
    "    def get_applause_yes_sentences(self):\n",
    "        return [s for s in self.sentences if s[2] == 1]\n",
    "    \n",
    "    def get_applause_no_sentences(self):\n",
    "        no_sentences = [s for s in self.sentences if s[2] == 0]\n",
    "        shuffle(no_sentences)\n",
    "        return no_sentences[0:len(self.get_applause_yes_sentences())]\n",
    "    \n",
    "    def get_sparse_liwc_features(self, sentence):\n",
    "        counts = {}\n",
    "        text = sentence.lower().split(' ')\n",
    "        for word in text:\n",
    "            cats=getLIWC(word)\n",
    "            for cat in cats:\n",
    "                if vocab[cat] in counts:\n",
    "                    counts[vocab[cat]] += 1  # = 1\n",
    "                else:\n",
    "                    counts[vocab[cat]] = 1.\n",
    "            if word in vocab:\n",
    "                if vocab[word] in counts:\n",
    "                    counts[vocab[word]] += 1  # = 1\n",
    "                else:\n",
    "                    counts[vocab[word]] = 1\n",
    "        return counts\n",
    "    \n",
    "    def get_dense_liwc_features(self,sentence):\n",
    "        a = np.zeros(len(vocab))\n",
    "        sparse_feats = self.get_sparse_liwc_features(sentence)\n",
    "        for k in sparse_feats.keys():\n",
    "            a[k-1] = float(sparse_feats[k]) / len(sentence)\n",
    "        return a\n",
    "        \n",
    "    def get_word_vec_features(self,sentence):\n",
    "        return nlp(sentence).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_transcripts = [Transcript(t) for t in transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_transcripts = []\n",
    "for t in all_transcripts:\n",
    "    if t.count_applause_instances() > 0:\n",
    "        good_transcripts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_transcript_paths = [t.filename for t in good_transcripts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('good_transcript_paths.txt','wb') as f:\n",
    "    for p in good_transcript_paths:\n",
    "        f.write(p + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('good_transcripts.pkl','wb') as f:\n",
    "    pickle.dump(good_transcripts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle, numpy as np\n",
    "with open('good_transcripts.pkl','rb') as f:\n",
    "    good_transcripts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ted_text_and_labels = []\n",
    "for t in tqdm(good_transcripts):\n",
    "    text_and_labels = [(str(t.sentences[i][0]),t.sentences[i][2]) for i in range(len(t.sentences))]\n",
    "    ted_text_and_labels.append(text_and_labels)\n",
    "    \n",
    "with open('/data/jrgillick/ted_text_and_labels.pkl','wb') as f:\n",
    "    pickle.dump(ted_text_and_labels,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alignments_dir = '/data/corpora/ted/forced_alignments/'\n",
    "alignments_files = os.listdir(alignments_dir)\n",
    "\n",
    "matched = []\n",
    "for t in good_transcripts:\n",
    "    matcher = t.filename.split(\"/\")[-1].replace(\".html\", \".json\")\n",
    "    if matcher in alignments_files:\n",
    "        matched.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_transcripts = []\n",
    "p = '/data/jrgillick/applause/transcripts/'\n",
    "paths = [p + path for path in os.listdir(p)]\n",
    "for path in paths:\n",
    "    with open(path, \"rb\") as f:\n",
    "        t = pickle.load(f)\n",
    "        all_transcripts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'evan_grant_cymatics.pkl'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store objects so we don't have to recompute features \n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_transcripts(filename=\"transripts.pkl\"):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(all_transcripts, f)\n",
    "\n",
    "def load_transcripts(filename=\"transcripts.pkl\"):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "transcripts_path = 'transcripts.pkl'\n",
    "\n",
    "if os.path.exists(transcripts_path):\n",
    "    all_transcripts = load_transcripts(transcripts_path)\n",
    "    \n",
    "else:\n",
    "    all_transcripts = [Transcript(f) for f in transcripts]\n",
    "    save_transcripts(transcripts_path)\n",
    "    \n",
    "#all_transcripts = shuffle(all_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = all_transcripts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Transcript instance has no attribute 'alignment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-707355b9ed5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_alignment_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-43d0f1561cc2>\u001b[0m in \u001b[0;36mget_alignment_times\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_alignment_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0malignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0malignment_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0malignment_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Transcript instance has no attribute 'alignment'"
     ]
    }
   ],
   "source": [
    "t.get_alignment_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_transcripts = []\n",
    "p = '/data/jrgillick/applause/transcripts/'\n",
    "files = [p+f for f in os.listdir(p)]\n",
    "for fl in files:\n",
    "    with open(fl) as f:\n",
    "        all_transcripts.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = all_transcripts[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = t.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(168,\n",
       "  u\"( Video )  Johnny  Cash :  \\u266b  There  ai n't  no  grave  \\u266b  \\u266b  can  hold  my  body  down  \\u266b  \\u266b  There  ai n't  no  grave  \\u266b  \\u266b  can  hold  body  down  \\u266b  \\u266b  When  I  hear  the  trumpet  sound  \\u266b  \\u266b  I 'm  going  to  ride  right  out  of  the  ground  \\u266b  \\u266b  Ai n't  no  grave  \\u266b  \\u266b  can  hold  my  body  ...  \\u266b\",\n",
       "  1)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,s[0],s[2]) for i,s in enumerate(sentences) if s[2]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[(i,s[0],s[2]) for i,s in enumerate(sentences) if i>105 and i<112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/data/corpora/ted/transcripts_clean/aaron_koblin.html'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296.98, 297.75)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 68\n",
    "t.alignment_times[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for t in all_transcripts:\n",
    "#    t.compute_alignments()\n",
    "#    t.compute_word_features()\n",
    "#    t.compute_word_count_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2:53.7'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cstm(t.alignment_times[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'3:6.3'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cstm(t.alignment_times[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = all_transcripts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 13)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t.sentence_audio_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_applause_yes_features(t):\n",
    "    features = []\n",
    "    sentences = t.sentences\n",
    "    for i in get_applause_indices(t):\n",
    "        features.append(get_feature(t,i))\n",
    "    return features\n",
    "\n",
    "def get_feature(t,i):\n",
    "    word_features = list(t.sentences[i][1])\n",
    "    audio_features = list(t.sentence_audio_features[i])\n",
    "    return word_features+audio_features\n",
    "\n",
    "def get_applause_indices(t):\n",
    "    return [i for i,s in enumerate(t.sentences) if s[2] == 1]\n",
    "\n",
    "def get_non_applause_indices(t):\n",
    "    return [i for i,s in enumerate(t.sentences) if s[2] != 1]\n",
    "\n",
    "def get_applause_no_features(t):\n",
    "    non_applause_indices = get_non_applause_indices(t)\n",
    "    shuffle(non_applause_indices)\n",
    "    features = []\n",
    "    for i in non_applause_indices[0:len(get_applause_indices(t))]:\n",
    "        features.append(get_feature(t,i))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 386)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(get_applause_no_features(t) + get_applause_no_features(t)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Run Logistic Regression Models </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import linear_model\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def get_balanced_applause_features(all_transcripts):\n",
    "    applause_yes = []\n",
    "    applause_no = []\n",
    "    for t in all_transcripts:\n",
    "        for a in t.get_applause_yes_sentences():\n",
    "            applause_yes.append(a[1])\n",
    "        for a in t.get_applause_no_sentences():\n",
    "            applause_no.append(a[1])\n",
    "    applause_yes = np.array(applause_yes)\n",
    "    applause_no = np.array(applause_no)\n",
    "    return applause_yes, applause_no\n",
    "\n",
    "def get_unbalanced_applause_features(all_transcripts):\n",
    "    applause_yes = []\n",
    "    applause_no = []\n",
    "    for t in all_transcripts:\n",
    "        for a in t.get_applause_yes_sentences():\n",
    "            applause_yes.append(a[1])\n",
    "        for a in t.sentences:\n",
    "            if a[2] == 0:\n",
    "                applause_no.append(a[1])\n",
    "    applause_yes = np.array(applause_yes)\n",
    "    applause_no = np.array(applause_no)\n",
    "    return applause_yes, applause_no\n",
    "\n",
    "def get_balanced_train_data_and_labels(all_transcripts):\n",
    "    applause_yes, applause_no = get_balanced_applause_features(all_transcripts)\n",
    "    X = np.vstack([applause_yes,applause_no])\n",
    "    Y = np.concatenate([np.ones(len(applause_yes)),np.zeros(len(applause_no))])\n",
    "    return X, Y\n",
    "\n",
    "def get_unbalanced_train_data_and_labels(all_transcripts):\n",
    "    applause_yes, applause_no = get_unbalanced_applause_features(all_transcripts)\n",
    "    X = np.vstack([applause_yes,applause_no])\n",
    "    Y = np.concatenate([np.ones(len(applause_yes)),np.zeros(len(applause_no))])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_balanced_applause_features_with_audio(all_transcripts):\n",
    "    applause_yes = []\n",
    "    applause_no = []\n",
    "    for t in all_transcripts:\n",
    "        applause_yes += get_applause_yes_features(t)\n",
    "        applause_no += get_applause_no_features(t)\n",
    "    return np.array(applause_yes), np.array(applause_no)\n",
    "\n",
    "def get_balanced_train_data_and_labels_with_audio(all_transcripts):\n",
    "    applause_yes, applause_no = get_balanced_applause_features_with_audio(all_transcripts)\n",
    "    X = np.vstack([applause_yes,applause_no])\n",
    "    Y = np.concatenate([np.ones(len(applause_yes)),np.zeros(len(applause_no))])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1910, 386)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_balanced_applause_features_with_audio(all_transcripts)[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression on balanced data following Liu et al. 2017</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.734 +/- 0.014 (2802/3820)'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_true = []\n",
    "total_pred = []\n",
    "\n",
    "X,Y = get_balanced_train_data_and_labels_with_audio(all_transcripts)\n",
    "X,Y = shuffle(X,Y)\n",
    "kf = KFold(len(Y), n_folds=10)\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    #X_train, X_test = X[train_index][:,73:], X[test_index][:,73:]\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    logreg=linear_model.LogisticRegression(penalty='l1',C=4)\n",
    "    clf = logreg\n",
    "    clf = GridSearchCV(logreg, {'C':(0.001, .01, .1, 1, 3, 4, 5)}, cv=3)\n",
    "    #clf = GridSearchCV(logreg, {'C':(3.5,4,4.5)}, cv=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #print(clf.best_params_, len(y_train))\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    for i in range(len(y_true)):\n",
    "        \n",
    "        total_true.append(y_true[i])\n",
    "        total_pred.append(y_pred[i])\n",
    "\n",
    "total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "acc=float(total_correct) / len(total_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision: 0.757 | Recall: 0.688 | F1: 0.721'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(total_true, total_pred)]\n",
    "str(\"Precision: %.3f | Recall: %.3f | F1: %.3f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'C': 4}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Run cross validation again with clean split on full talks rather than sentences </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.722 +/- 0.014 (2759/3820)'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_true = []\n",
    "total_pred = []\n",
    "\n",
    "kf = KFold(len(all_transcripts), n_folds=10)\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "    X_train, y_train = get_balanced_train_data_and_labels_with_audio(t_train)\n",
    "    X_test, y_test = get_balanced_train_data_and_labels_with_audio(t_test)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "    #X_train, X_test = X_train[:,0:73], X_test[:,0:73]\n",
    "    \n",
    "    logreg=linear_model.LogisticRegression(penalty='l1',C=3)\n",
    "    clf = logreg\n",
    "\n",
    "    clf = GridSearchCV(logreg, {'C':(3,3.5,4,4.5)}, cv=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    for i in range(len(y_true)):\n",
    "        \n",
    "        total_true.append(y_true[i])\n",
    "        total_pred.append(y_pred[i])\n",
    "\n",
    "total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "acc=float(total_correct) / len(total_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision: 0.746 | Recall: 0.674 | F1: 0.708'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(total_true, total_pred)]\n",
    "str(\"Precision: %.3f | Recall: %.3f | F1: %.3f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'C': 3.5}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Train on balanced subset, test on full talks </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.553 +/- 0.003 (71471/129189)'"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_true = []\n",
    "total_pred = []\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "    X_train, y_train = get_balanced_train_data_and_labels(t_train)\n",
    "    X_test, y_test = get_unbalanced_train_data_and_labels(t_test)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "    X_train, X_test = X_train[:,73:], X_test[:,73:]\n",
    "    \n",
    "    logreg=linear_model.LogisticRegression(penalty='l1')\n",
    "    clf = logreg\n",
    "\n",
    "    clf = GridSearchCV(logreg, {'C':(3,3.5,4,4.5)}, cv=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    for i in range(len(y_true)):\n",
    "        \n",
    "        total_true.append(y_true[i])\n",
    "        total_pred.append(y_pred[i])\n",
    "\n",
    "total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "acc=float(total_correct) / len(total_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision: 0.022 | Recall: 0.663 | F1: 0.043'"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(total_true, total_pred)]\n",
    "str(\"Precision: %.3f | Recall: %.3f | F1: %.3f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'C': 4.5}"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Train on full talks, test on full talks </h3>\n",
    "This takes a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.985 +/- 0.001 (127233/129189)'"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_true = []\n",
    "total_pred = []\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "    X_train, y_train = get_unbalanced_train_data_and_labels(t_train)\n",
    "    X_test, y_test = get_unbalanced_train_data_and_labels(t_test)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "    X_train, X_test = X_train[:,73:], X_test[:,73:]\n",
    "    \n",
    "    logreg=linear_model.LogisticRegression(penalty='l1')\n",
    "    clf = logreg\n",
    "    clf = GridSearchCV(logreg, {'C':(0.001, .01, .1, 1, 3, 5)}, cv=3)\n",
    "    #clf = GridSearchCV(logreg, {'C':(3,3.5,4,4.5)}, cv=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    for i in range(len(y_true)):      \n",
    "        total_true.append(y_true[i])\n",
    "        total_pred.append(y_pred[i])\n",
    "\n",
    "total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "acc=float(total_correct) / len(total_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision: 0.000 | Recall: 0.000 | F1: 0.000'"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(total_true, total_pred)]\n",
    "str(\"Precision: %.3f | Recall: %.3f | F1: %.3f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'C': 3.5}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> MLP on a single sentence </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, Dropout\n",
    "import keras.optimizers\n",
    "from keras.models import load_model\n",
    "import keras.regularizers\n",
    "from keras.regularizers import l2, l1\n",
    "\n",
    "def initialize_mlp2():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(600, use_bias=True,input_dim=613))#1924\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def initialize_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(600, use_bias=True,input_dim=386))#1924\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = initialize_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(all_transcripts), n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "#X_train, y_train = get_balanced_train_data_and_labels(t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (None, 386) but got array with shape (3105, 300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-9fedf7ef8a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrgillick/.local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/jrgillick/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrgillick/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1306\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1307\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrgillick/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (None, 386) but got array with shape (3105, 300)"
     ]
    }
   ],
   "source": [
    "#Keras model FF\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "total_true = []\n",
    "total_pred = []\n",
    "\n",
    "for train_index, test_index in kf:  \n",
    "    t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "    X_train, y_train = get_balanced_train_data_and_labels_with_audio(t_train)\n",
    "    X_test, y_test = get_balanced_train_data_and_labels_with_audio(t_test)\n",
    "    \n",
    "    for i in xrange(X_train.shape[1]):\n",
    "        mean = np.mean(X_train[:,i])\n",
    "        X_train[:,i] -= mean\n",
    "        X_test[:,i] -=mean\n",
    "        std = np.std(X_train[:,i])\n",
    "        X_train[:,i] /= std\n",
    "        X_test[:,i] /= std\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_test, y_test = shuffle(X_test, y_test)\n",
    "    \n",
    "    #X_train = sklearn.preprocessing.normalize(X_train,return_norm=True)\n",
    "\n",
    "    X_train_words, X_test_words = X_train[:,73:373], X_test[:,73:373]\n",
    "    X_train_audio, X_test_audio = X_train[:,373:], X_test[:,373:]\n",
    "\n",
    "    best_acc = 0\n",
    "    m = initialize_mlp()\n",
    "    val_index = int(len(X_train)*0.9)\n",
    "    val_data, val_labels = (X_train_words[val_index:], y_train[val_index:])\n",
    "    train_data, train_labels = (X_train_words[0:val_index], y_train[0:val_index])\n",
    "\n",
    "    max_epochs = 30; e = 0\n",
    "    while e < max_epochs:                            \n",
    "        m.fit(X_train_words[0:val_index], y_train[0:val_index], nb_epoch=1,batch_size=128,shuffle=True)\n",
    "        acc = m.evaluate(val_data, val_labels)[1]\n",
    "        if acc > best_acc: \n",
    "            best_acc = acc\n",
    "            m.save('best_ff_model.h5')\n",
    "        e+=1\n",
    "\n",
    "    m = load_model('best_ff_model.h5')\n",
    "    \n",
    "    word_features_train = np.maximum(np.dot(X_train_words,m.get_weights()[0]) + m.get_weights()[1],0)\n",
    "    audio_features_train = X_train_audio\n",
    "    all_features_train = np.hstack([word_features_train,audio_features_train])\n",
    "    \n",
    "    word_features_test = np.maximum(np.dot(X_test_words,m.get_weights()[0]) + m.get_weights()[1],0)\n",
    "    audio_features_test = X_test_audio\n",
    "    all_features_test = np.hstack([word_features_test,audio_features_test])\n",
    "    \n",
    "    m2 = initialize_mlp2()\n",
    "    max_epochs = 120; e = 0\n",
    "    best_acc2 = 0\n",
    "    while e < max_epochs:                            \n",
    "        m2.fit(all_features_train[0:val_index], y_train[0:val_index], nb_epoch=1,batch_size=128,shuffle=True)\n",
    "        acc2 = m2.evaluate(all_features_train[val_index:], val_labels)[1]\n",
    "        if acc2 > best_acc2: \n",
    "            best_acc2 = acc2\n",
    "            m2.save('best_ff_model2.h5')\n",
    "        e+=1\n",
    "\n",
    "    m2 = load_model('best_ff_model2.h5')\n",
    "    \n",
    "    #logreg=linear_model.LogisticRegression(penalty='l1',C=3.5)\n",
    "    #clf = logreg\n",
    "\n",
    "    #clf = GridSearchCV(logreg, {'C':(3,3.5,4,4.5)}, cv=3)\n",
    "    #clf.fit(all_features_train, y_train)\n",
    "    \n",
    "    #y_true, y_pred = y_test, clf.predict(all_features_test)\n",
    "\n",
    "    y_true, y_pred = y_test, np.round(m2.predict(all_features_test))\n",
    "    for i in range(len(y_true)):\n",
    "        total_true.append(y_true[i])\n",
    "        total_pred.append(y_pred[i][0])\n",
    "        \n",
    "        \n",
    "\n",
    "total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "acc=float(total_correct) / len(total_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.709 +/- 0.014 (2708/3820)'"
      ]
     },
     "execution_count": 1489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision: 0.715 | Recall: 0.695 | F1: 0.705'"
      ]
     },
     "execution_count": 1490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(total_true, total_pred)]\n",
    "str(\"Precision: %.3f | Recall: %.3f | F1: %.3f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_balanced_train_data_and_labels_with_audio(t_train)\n",
    "X_test, y_test = get_balanced_train_data_and_labels_with_audio(t_test)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "for i in xrange(X_train.shape[1]):\n",
    "    mean = np.mean(X_train[:,i])\n",
    "    X_train[:,i] -= mean\n",
    "    X_test[:,i] -=mean\n",
    "    std = np.std(X_train[:,i])\n",
    "    X_train[:,i] /= std\n",
    "    X_test[:,i] /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(150, use_bias=True,input_dim=313))#1924\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "for train_index, test_index in kf:\n",
    "    indices.append((train_index,test_index))\n",
    "#t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "#X_train, y_train = get_balanced_train_data_and_labels_with_audio(t_train)\n",
    "#X_test, y_test = get_balanced_train_data_and_labels_with_audio(t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_index, test_index = indices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "X_train, y_train = get_balanced_train_data_and_labels_with_audio(t_train)\n",
    "X_test, y_test = get_balanced_train_data_and_labels_with_audio(t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "for i in xrange(X_train.shape[1]):\n",
    "    mean = np.mean(X_train[:,i])\n",
    "    X_train[:,i] -= mean\n",
    "    X_test[:,i] -=mean\n",
    "    std = np.std(X_train[:,i])\n",
    "    X_train[:,i] /= std\n",
    "    X_test[:,i] /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = initialize_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f37fedb6150>"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X_train[:,73:],y_train,epochs=20,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.69314718575691603, 0.50000000078878415]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(X_train[:,73:],y_train,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.69314719078152676, 0.50000000970308167]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(X_test[:,73:],y_test,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, np.round(m.predict(X_test[:,73:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_true = []\n",
    "total_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.752 +/- 0.041 (313/416)'"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(y_true)):\n",
    "    total_true.append(y_true[i])\n",
    "    total_pred.append(y_pred[i][0])\n",
    "        \n",
    "        \n",
    "\n",
    "total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "acc=float(total_correct) / len(total_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(all_transcripts), n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(m.predict_classes(X_train,batch_size=512) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.716 +/- 0.014 (2734/3820)'"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keras model FF\n",
    "\n",
    "total_true = []\n",
    "total_pred = []\n",
    "\n",
    "for train_index, test_index in kf:  \n",
    "    t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "    X_train, y_train = get_balanced_train_data_and_labels_with_audio(t_train)\n",
    "    X_test, y_test = get_balanced_train_data_and_labels_with_audio(t_test)\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "    for i in xrange(X_train.shape[1]):\n",
    "        mean = np.mean(X_train[:,i])\n",
    "        X_train[:,i] -= mean\n",
    "        X_test[:,i] -=mean\n",
    "        std = np.std(X_train[:,i])\n",
    "        X_train[:,i] /= std\n",
    "        X_test[:,i] /= std\n",
    "    \n",
    "    m = initialize_mlp()\n",
    "\n",
    "    m.fit(X_train[:,73:],y_train,epochs=50,batch_size=128)\n",
    "    \n",
    "    y_true, y_pred = y_test, np.round(m.predict(X_test[:,73:]))\n",
    "    for i in range(len(y_true)):\n",
    "        total_true.append(y_true[i])\n",
    "        total_pred.append(y_pred[i][0])\n",
    "        \n",
    "        \n",
    "\n",
    "total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "acc=float(total_correct) / len(total_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 386)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision: 0.749 | Recall: 0.648 | F1: 0.695'"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(total_true, total_pred)]\n",
    "str(\"Precision: %.3f | Recall: %.3f | F1: %.3f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty=u'l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_balanced_train_data_and_labels_with_audio(t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3440, 386)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3440, 300)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_words = X_train[:,73:373]\n",
    "X_train_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_features = np.maximum(np.dot(X_train_words,m.get_weights()[0]) + m.get_weights()[1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_features = X_train[:,373:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = np.hstack([word_features, audio_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3440, 613)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_weights()[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train LSTM over series of 5 Sentences </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1852,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 1852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1853,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_applause_indices(transcript):\n",
    "    a = [s[2] for s in transcript.sentences]\n",
    "    return list(np.nonzero(a)[0])\n",
    "\n",
    "def get_non_applause_indices(transcript):\n",
    "    return [index for index, s in enumerate(transcript.sentences) if s[2] == 0]\n",
    "\n",
    "def extract_features_from_sentence_list(l):\n",
    "    return np.array([s[1] for s in l])\n",
    "\n",
    "def extract_applause_sequences(transcript,num_sentences):\n",
    "    applause_indices = [i for i in get_applause_indices(transcript) if i > num_sentences-1]\n",
    "    sentence_lists = [transcript.sentences[i-num_sentences+1:i+1] for i in applause_indices]\n",
    "    feature_lists = [extract_features_from_sentence_list(s) for s in sentence_lists]\n",
    "    return np.array(feature_lists)\n",
    "\n",
    "def extract_non_applause_sequences(transcript,num_sentences,n):\n",
    "    non_applause_indices = [i for i in get_non_applause_indices(transcript) if i > num_sentences-1]\n",
    "    non_applause_indices = shuffle(non_applause_indices)[0:n]\n",
    "    sentence_lists = [transcript.sentences[i-num_sentences+1:i+1] for i in non_applause_indices]\n",
    "    return np.array([extract_features_from_sentence_list(s) for s in sentence_lists])\n",
    "\n",
    "def extract_applause_sequences_with_audio(transcript,num_sentences):\n",
    "    applause_indices = [i for i in get_applause_indices(transcript) if i > num_sentences-1]\n",
    "    index_lists = [list(range(i-num_sentences+1,i+1)) for i in applause_indices]\n",
    "    feature_lists = [[get_feature(transcript,i) for i in index_list] for index_list in index_lists]\n",
    "    return np.array(feature_lists)\n",
    "\n",
    "def extract_non_applause_sequences_with_audio(transcript,num_sentences,n):\n",
    "    non_applause_indices = [i for i in get_non_applause_indices(transcript) if i > num_sentences-1]\n",
    "    non_applause_indices = shuffle(non_applause_indices)[0:n]\n",
    "    index_lists = [list(range(i-num_sentences+1,i+1)) for i in non_applause_indices]\n",
    "    feature_lists = [[get_feature(transcript,i) for i in index_list] for index_list in index_lists]\n",
    "    return np.array(feature_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1854,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_in_sentence(sentence):\n",
    "    return [word for word in nlp(sentence) if re.search(\"\\S\", word.string) != None]\n",
    "\n",
    "def count_words_in_sentence(sentence):\n",
    "    return len(get_words_in_sentence(sentence))\n",
    "\n",
    "def get_num_previous_words(transcript, index): \n",
    "    return int(np.sum([count_words_in_sentence(s) for s in [s[0] for s in transcript.sentences[0:index]]]))\n",
    "\n",
    "def get_vector_list_from_word_list(word_list):\n",
    "    return [word.vector for word in word_list]\n",
    "\n",
    "def get_preceding_words(transcript, index, num_words):\n",
    "    sentences = [s[0] for s in transcript.sentences]\n",
    "    words = []\n",
    "    i = index\n",
    "    while len(words) < num_words:\n",
    "        words = get_words_in_sentence(sentences[i]) + words\n",
    "        i -= 1\n",
    "    return words[len(words)-num_words:]\n",
    "\n",
    "def get_preceding_word_vectors(transcript, index, num_words):\n",
    "    vecs = []\n",
    "    i = index\n",
    "    while len(vecs) < num_words:\n",
    "        #vecs = list(transcript.sentences[i][3]) + vecs\n",
    "        vecs = list(transcript.word_features[i]) + vecs\n",
    "    return (vecs)[-num_words:]\n",
    "    \n",
    "def extract_applause_word_sequences(transcript, num_words):\n",
    "    applause_indices = [i for i in get_applause_indices(transcript) if t.count_preceding_words(i) > num_words]\n",
    "    vector_lists = [get_preceding_word_vectors(transcript, i, num_words) for i in applause_indices]\n",
    "    #word_lists = [get_preceding_words(transcript, i, num_words) for i in applause_indices]\n",
    "    #vector_lists = [get_vector_list_from_word_list(wl) for wl in word_lists]\n",
    "    return np.array(vector_lists)\n",
    "\n",
    "def extract_non_applause_word_sequences(transcript,num_words,n):\n",
    "    non_applause_indices = [i for i in get_non_applause_indices(transcript) if t.count_preceding_words(i) > num_words]\n",
    "    non_applause_indices = shuffle(non_applause_indices)[0:n]\n",
    "    vector_lists = [get_preceding_word_vectors(transcript, i, num_words) for i in non_applause_indices]\n",
    "    #word_lists = [get_preceding_words(transcript, i, num_words) for i in non_applause_indices]\n",
    "    #vector_lists = [get_vector_list_from_word_list(wl) for wl in word_lists]\n",
    "    return np.array(vector_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1855,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 373\n",
    "n_categories = 1\n",
    "n_hidden=200\n",
    "num_sentences = 5\n",
    "number_of_layers=1\n",
    "learning_rate = 0.1\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Extract applause with a context of 4 previous sentences and train LSTM on balanced data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1856,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_balanced_lstm_applause_features(all_transcripts, sequence_len, sequence_type = 'sentence'):\n",
    "    applause_yes = None\n",
    "    applause_no = None\n",
    "    for t in all_transcripts:\n",
    "        if sequence_type == 'sentence':\n",
    "            positives = extract_applause_sequences_with_audio(t,sequence_len)\n",
    "            negatives = extract_non_applause_sequences_with_audio(t,sequence_len,len(positives))\n",
    "        elif sequence_type == 'word':\n",
    "            positives = extract_applause_word_sequences(t,sequence_len)\n",
    "            negatives = extract_non_applause_word_sequences(t,sequence_len,len(positives))\n",
    "        if len(positives) != 0:\n",
    "            if applause_yes is None:\n",
    "                applause_yes = positives\n",
    "                applause_no = negatives\n",
    "            else:\n",
    "                applause_yes = np.vstack([applause_yes, positives])\n",
    "                applause_no = np.vstack([applause_no, negatives])\n",
    "    return applause_yes, applause_no\n",
    "\n",
    "def format_label(l, sequence_len):\n",
    "    return np.array(list(np.zeros(sequence_len-1)) + [l]).reshape((sequence_len,1))\n",
    "\n",
    "def train_tf(train_data, train_labels):\n",
    "    for i in range(len(train_data)):\n",
    "        sess.run(optimizer,feed_dict={x:train_data[i],y:train_labels[i].reshape((5,1)),seq_length:num_sentences})\n",
    "        \n",
    "def evaluate_on_data(test_data, test_labels):\n",
    "    num_correct = 0\n",
    "    for i in range(len(test_data)):\n",
    "        num_correct += sess.run(accuracy,feed_dict={x:test_data[i],y:test_labels[i].reshape((5,1)),seq_length:num_sentences})\n",
    "    return(num_correct / len(test_data))\n",
    "\n",
    "def predict_on_data(test_data):\n",
    "    return [np.round(sess.run(prediction,feed_dict={x:test_data[i],seq_length:num_sentences}))[0][0] for i in range(len(test_data))]\n",
    "\n",
    "def get_balanced_lstm_features_and_labels(all_transcripts, sequence_len, sequence_type = 'sentence'):\n",
    "    applause_yes, applause_no = get_balanced_lstm_applause_features(all_transcripts, sequence_len, sequence_type = sequence_type)\n",
    "    X = np.vstack([applause_yes,applause_no])\n",
    "    Y = np.concatenate([np.ones(len(applause_yes)),np.zeros(len(applause_no))])\n",
    "    Y = np.array([format_label(l, sequence_len) for l in Y]).reshape((len(Y),-1))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up tensorflow graph\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, n_features])\n",
    "y = tf.placeholder(tf.float32, [None, n_categories])\n",
    "seq_length = tf.placeholder(tf.int32)\n",
    "\n",
    "weights = {'out': tf.Variable(tf.random_normal([n_hidden, n_categories])),}\n",
    "biases = {'out': tf.Variable(tf.random_normal([n_categories]))}\n",
    "\n",
    "fc1 = tf.reshape(x, [1, -1, n_features])\n",
    "lstm_fw_cell = BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "lstm_fw_multicell = tf.contrib.rnn.MultiRNNCell([lstm_fw_cell] * number_of_layers, state_is_tuple=True)\n",
    "\n",
    "output_fw, state_fw = tf.nn.dynamic_rnn(lstm_fw_multicell,fc1,dtype='float32',sequence_length=tf.reshape(seq_length, [1]))\n",
    "outputs_fw = tf.reshape(output_fw, [seq_length, n_hidden])\n",
    "out = tf.matmul(outputs_fw, weights['out']) + biases['out']\n",
    "pred = tf.gather(out,[num_sentences-1])\n",
    "end_label = tf.gather(y,[num_sentences-1])\n",
    "#end_label = tf.reshape(tf.gather(tf.reshape(y,[-1]),[num_sentences-1]),[1,1])\n",
    "\n",
    "cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=end_label)\n",
    "cost2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=out, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)#(learning_rate=0.1, l2_regularization_strength=0.1).minimize(cost)\n",
    "#optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate, l2_regularization_strength=1.0).minimize(cost)\n",
    "prediction = tf.sigmoid(pred)\n",
    "correct_pred = tf.equal(tf.greater_equal(prediction,0.5), tf.equal(end_label,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kf = KFold(len(all_transcripts), n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_balanced_lstm_features_and_labels() got an unexpected keyword argument 'num_sentences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c65a2b2eda0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_transcripts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_transcripts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_balanced_lstm_features_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_balanced_lstm_features_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_balanced_lstm_features_and_labels() got an unexpected keyword argument 'num_sentences'"
     ]
    }
   ],
   "source": [
    "total_true = []\n",
    "total_pred = []\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "    \n",
    "    X_train, y_train = get_balanced_lstm_features_and_labels(t_train, num_sentences=5)\n",
    "    X_test, y_test = get_balanced_lstm_features_and_labels(t_test, num_sentences=5)\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_test, y_test = shuffle(X_test, y_test)\n",
    "    #X_train, X_test = X_train[:,:,73:], X_test[:,:,73:]\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_weights = np.zeros(n_hidden)\n",
    "    best_bias = 0.\n",
    "    val_index = int(len(X_train)*0.9)\n",
    "    val_data, val_labels = (X_train[val_index:], y_train[val_index:])\n",
    "    train_data, train_labels = (X_train[0:val_index], y_train[0:val_index])\n",
    "    \n",
    "    max_epochs = 10\n",
    "    sess.run(init)\n",
    "    for i in range(max_epochs):\n",
    "        train_data, train_labels = shuffle(train_data, train_labels)\n",
    "        train_tf(train_data, train_labels)\n",
    "        acc = evaluate_on_data(val_data, val_labels)\n",
    "        if acc > best_acc: \n",
    "            best_acc = acc\n",
    "            best_weights = sess.run(weights['out'])\n",
    "            best_bias = sess.run(biases['out'])\n",
    "        \n",
    "    assign_weights_op = tf.assign(weights['out'], best_weights)\n",
    "    assign_bias_op = tf.assign(biases['out'], best_bias)\n",
    "    sess.run(assign_weights_op)\n",
    "    y_true, y_pred = y_test[:,num_sentences-1], predict_on_data(X_test)\n",
    "    \n",
    "    for i in range(len(y_true)):      \n",
    "        total_true.append(y_true[i])\n",
    "        total_pred.append(y_pred[i])\n",
    "\n",
    "total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "acc=float(total_correct) / len(total_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(total_true, total_pred)]\n",
    "str(\"Precision: %.3f | Recall: %.3f | F1: %.3f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Implement LSTM again in Keras to compare </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1857,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, Dropout\n",
    "import keras.optimizers\n",
    "from keras.models import load_model\n",
    "import keras.regularizers\n",
    "from keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.layers import regularizers\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "def initialize_lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.5,input_shape=(2,313)))\n",
    "    #model.add(Conv1D(6,3,padding='same',input_shape=(5, 386)))\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(MaxPooling1D(pool_size=3))\n",
    "    #model.add(Conv1D(36,3,padding='same'))\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(MaxPooling1D(pool_size=3))\n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(LSTM(100,input_shape=(None,313),return_sequences=False,dropout=0.8))\n",
    "    #model.add(Bidirectional(LSTM(200, return_sequences=True, dropout=0.8),input_shape=(None, 313)))\n",
    "    #model.add(Bidirectional(LSTM(100, return_sequences=False, dropout=0.5),input_shape=(None, 313)))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    #model.add(LSTM(50,return_sequences=False))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = initialize_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data_2 = np.array([t [3:,:] for t in train_data])\n",
    "#test_data_2 = np.array([t [3:,:] for t in test_data])\n",
    "#train_data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "692.8000000000001"
      ]
     },
     "execution_count": 2265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_transcripts)*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_train = all_transcripts[0:693]\n",
    "t_test = all_transcripts[693:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_balanced_lstm_features_and_labels(t_train, sequence_len=2, sequence_type='sentence')\n",
    "X_test, y_test = get_balanced_lstm_features_and_labels(t_test, sequence_len=2, sequence_type='sentence')\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2982, 2, 386)"
      ]
     },
     "execution_count": 2268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = X_train.shape\n",
    "s2 = X_test.shape\n",
    "temp_x_train = X_train.reshape((s[0]*s[1],s[2]))\n",
    "temp_x_test = X_test.reshape((s2[0]*s2[1],s2[2]))\n",
    "for i in xrange(temp_x_train.shape[1]):\n",
    "    mean = np.mean(temp_x_train[:,i])\n",
    "    temp_x_train[:,i] -= mean\n",
    "    temp_x_test[:,i] -=mean\n",
    "    std = np.std(temp_x_train[:,i])\n",
    "    temp_x_train[:,i] /= std\n",
    "    temp_x_test[:,i] /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = temp_x_train.reshape(s)\n",
    "X_test = temp_x_test.reshape(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2982, 2, 313)"
      ]
     },
     "execution_count": 2271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[:,:,73:]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test[:,:,73:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = initialize_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75c2a39310>"
      ]
     },
     "execution_count": 2349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X_train, y_train[:,-1], nb_epoch=1, batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32114363478223085, 0.88598256035989598]"
      ]
     },
     "execution_count": 2350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(X_train,y_train[:,-1],batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62136490557128021, 0.67042604335268641]"
      ]
     },
     "execution_count": 2351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(X_test,y_test[:,-1],batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(all_transcripts), n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keras model\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "\n",
    "total_true = []\n",
    "total_pred = []\n",
    "\n",
    "for train_index, test_index in kf:  \n",
    "    t_train, t_test = np.array(all_transcripts)[train_index], np.array(all_transcripts)[test_index]\n",
    "    \n",
    "    X_train, y_train = get_balanced_lstm_features_and_labels(t_train, sequence_len=36, sequence_type='word')\n",
    "    X_test, y_test = get_balanced_lstm_features_and_labels(t_test, sequence_len=36, sequence_type='word')\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_test, y_test = shuffle(X_test, y_test)\n",
    "    \n",
    "    # Don't include labels for the whole sequence as we're only predicting at the end of the sequence\n",
    "    y_train = np.array([l[-1] for l in y_train])\n",
    "    y_test = np.array([l[-1] for l in y_test])\n",
    "    \n",
    "    best_acc = 0\n",
    "    m = initialize_lstm_model()\n",
    "    val_index = int(len(X_train)*0.9)\n",
    "    val_data, val_labels = (X_train[val_index:], y_train[val_index:])\n",
    "    train_data, train_labels = (X_train[0:val_index], y_train[0:val_index])\n",
    "    \n",
    "    max_epochs = 1; e = 0\n",
    "    while e < max_epochs:                            \n",
    "        m.fit(X_train[0:val_index], y_train[0:val_index], nb_epoch=1,batch_size=128,shuffle=True)\n",
    "        acc = m.evaluate(val_data, val_labels)[1]\n",
    "        if acc > best_acc: \n",
    "            best_acc = acc\n",
    "            m.save('best_model.h5')\n",
    "        e+=1\n",
    "        \n",
    "    m = load_model('best_model.h5')\n",
    "    \n",
    "    y_true, y_pred = y_test, np.round(m.predict(X_test))\n",
    "    for i in range(len(y_true)):\n",
    "        total_true.append(y_true[i])\n",
    "        total_pred.append(y_pred[i][0])\n",
    "    \n",
    "total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "acc=float(total_correct) / len(total_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "str(\"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(total_true, total_pred)]\n",
    "str(\"Precision: %.3f | Recall: %.3f | F1: %.3f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
