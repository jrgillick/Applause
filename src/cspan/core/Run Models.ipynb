{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, pickle\n",
    "from IPython.display import Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import featurizer, data_formatter, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/jrgillick/speeches.pkl') as f:\n",
    "    speeches = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "with open('/data/jrgillick/individual_feature_lists.pkl') as f:\n",
    "    individual_feature_lists = pickle.load(f)\n",
    "print \"load in \" + str(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speaker_names = ['donald_trump',\n",
    " 'hilary_clinton',\n",
    " 'bernie_sanders',\n",
    " 'ted_cruz',\n",
    " 'marco_rubio',\n",
    " 'john_kasich',\n",
    " 'barack_obama',\n",
    " 'bill_clinton',\n",
    " 'joe_biden',\n",
    " 'mike_pence',\n",
    " 'carly_fiorina',\n",
    " 'jeb_bush',\n",
    " 'rand_paul',\n",
    " 'gary_johnson',\n",
    " 'chris_christie',\n",
    " 'rick_santorum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for s in speeches:\n",
    "#    phrase_list = s.alignment.get_phrase_text()\n",
    "#    with open('/data/corpora/cspan/phrase_lists/' + s.file_path.split('/')[1] + '.txt','wb') as f:\n",
    "#        for p in phrase_list:\n",
    "#            f.write(p + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [30:49<00:00,  5.54s/it]\n"
     ]
    }
   ],
   "source": [
    "speeches = [speech.Speech(s.file_path.split('/')[1]) for s in tqdm(speeches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in speeches:\n",
    "    s.phrase_audio_features = s.get_phrase_audio_features()\n",
    "    normalize_phrase_audio_features(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(X_train, X_test):\n",
    "    new_X_train = np.copy(X_train)\n",
    "    new_X_test = np.copy(X_test)\n",
    "    for i in xrange(new_X_train.shape[1]):\n",
    "        if set(new_X_train[:,i]) != set([0,1]) and set(new_X_train[:,i]) != set([0]) and set(new_X_train[:,i]) != set([1]):\n",
    "            #print 'norming'\n",
    "            #print set(new_X_train[:,i])\n",
    "            mean = np.mean(new_X_train[:,i])\n",
    "            new_X_train[:,i] -= mean\n",
    "            new_X_test[:,i] -=mean\n",
    "            std = np.std(X_train[:,i])\n",
    "            if std > 1e-2:\n",
    "                new_X_train[:,i] /= std\n",
    "                new_X_test[:,i] /= std\n",
    "    return new_X_train, new_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "individual_feature_lists = []\n",
    "for i in range(len(train_speeches)):\n",
    "    h = {'id': train_speeches[i].file_path,\n",
    "         'bigrams': train_bigram_feats[i],\n",
    "         'rst': train_rst_feats[i],\n",
    "         'audio': train_audio_feats[i],\n",
    "         'euphony': train_euphony_feats[i],\n",
    "         'liu': train_liu_feats[i],\n",
    "         'cosine': np.array(train_cosine_feats[i]).reshape(-1,1),\n",
    "         'phone': train_phone_feats[i],\n",
    "         'substring': np.array(train_substring_feats[i]).reshape(-1,1),\n",
    "         'word_overlap': np.array(train_word_overlap_feats[i]).reshape(-1,1),\n",
    "         'labels': train_labels[i]}\n",
    "    individual_feature_lists.append(h)\n",
    "    \n",
    "for i in range(len(test_speeches)):\n",
    "    h = {'id': test_speeches[i].file_path,\n",
    "         'bigrams': test_bigram_feats[i],\n",
    "         'rst': test_rst_feats[i],\n",
    "         'audio': test_audio_feats[i],\n",
    "         'euphony': test_euphony_feats[i],\n",
    "         'liu': test_liu_feats[i],\n",
    "         'cosine': np.array(test_cosine_feats[i]).reshape(-1,1),\n",
    "         'phone': test_phone_feats[i],\n",
    "         'substring': np.array(test_substring_feats[i]).reshape(-1,1),\n",
    "         'word_overlap': np.array(test_word_overlap_feats[i]).reshape(-1,1),\n",
    "         'labels': test_labels[i]}\n",
    "    individual_feature_lists.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_and_test_sets(speaker_name):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for i in range(len(individual_feature_lists)):\n",
    "        if speaker_name in individual_feature_lists[i]['id']:\n",
    "            test_set.append(individual_feature_lists[i])\n",
    "        else:\n",
    "            train_set.append(individual_feature_lists[i])\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(data_set, feature_names):\n",
    "    all_feats = []\n",
    "    for i in range(len(data_set)):\n",
    "        feats = [data_set[i][name] for name in feature_names]\n",
    "        all_feats.append(np.hstack(feats))\n",
    "    return all_feats\n",
    "\n",
    "def get_labels(data_set):\n",
    "    all_labels = []\n",
    "    for i in range(len(data_set)):\n",
    "        all_labels.append(data_set[i]['labels'])\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28832, 26859)\n"
     ]
    }
   ],
   "source": [
    "feature_set = ['bigrams','audio','liu','euphony','phone','cosine','substring','word_overlap','rst']\n",
    "phrase_count = 1\n",
    "\n",
    "train_set = individual_feature_lists[0:248]\n",
    "test_set = individual_feature_lists[248:]\n",
    "\n",
    "labels_train = get_labels(train_set)\n",
    "data_train = get_features(train_set,feature_set)\n",
    "\n",
    "labels_test = get_labels(test_set)\n",
    "data_test = get_features(test_set,feature_set)\n",
    "\n",
    "current_train_formatted_feats, current_train_formatted_labs = models.format_balanced_multiple_phrase_input(data_train,labels_train,phrase_count=phrase_count)\n",
    "current_test_formatted_feats, current_test_formatted_labs = models.format_balanced_multiple_phrase_input(data_test,labels_test,phrase_count=phrase_count)\n",
    "\n",
    "X_train = np.array(current_train_formatted_feats).astype('float64')\n",
    "y_train = np.array(current_train_formatted_labs)\n",
    "        \n",
    "print X_train.shape\n",
    "\n",
    "X_test = np.array(current_test_formatted_feats).astype('float64')\n",
    "y_test = np.array(current_test_formatted_labs)\n",
    "\n",
    "#X_train, X_test = normalize_data(X_train,X_test)\n",
    "#model = models.train_cv_logistic_regression_faster(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, jeb_train = normalize_data(X_train, np.array(jeb_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefs = model.best_estimator_.coef_[0]\n",
    "#coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jeb_speech, jeb_featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeb = jeb_speech.Speech('jeb')\n",
    "f = jeb_featurizer.Featurizer(jeb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature_set = ['bigrams','audio','liu','euphony','phone','cosine','substring','word_overlap','rst']\n",
    "jeb_feats =np.hstack([np.array(f.get_bigram_features()),\n",
    "           np.array(f.get_audio_features()),\n",
    "           np.array(f.get_liu_features()),\n",
    "           np.array(f.get_euphony_features()),\n",
    "           np.array(f.get_phone_features()),\n",
    "           np.array(f.get_vector_cosine_distances()).reshape(-1,1),\n",
    "           np.array(f.get_common_substring_features()).reshape(-1,1),\n",
    "           np.array(f.get_n_common_words()).reshape(-1,1),\n",
    "           np.array(f.get_rst_features()),\n",
    "          ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeb_order_0 = np.argsort(jeb_train[0] * coefs)\n",
    "jeb_order_1 = np.argsort(jeb_train[1] * coefs)\n",
    "jeb_order_2 = np.argsort(jeb_train[2] * coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 26859)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09509445,  0.04586393,  0.0455949 , ..., -0.05811358,\n",
       "        0.00184465, -0.1136884 ])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = {'coefs':coefs,'feature_names':all_feature_names,'jeb_features':jeb_train}\n",
    "jeb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/corpora/cspan/jeb_coefs.pkl','wb') as f:\n",
    "    pickle.dump(h,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/corpora/cspan/jeb_coefs.pkl','rb') as f:\n",
    "    h = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 26859)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h['jeb_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeb_0_activations = zip(np.array(all_feature_names)[jeb_order_0], jeb_train[0]*coefs)\n",
    "jeb_1_activations = zip(np.array(all_feature_names)[jeb_order_1], jeb_train[1]*coefs[jeb_order_1])\n",
    "jeb_2_activations = zip(np.array(all_feature_names)[jeb_order_2], jeb_train[2]*coefs[jeb_order_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'be_a', 0.0),\n",
       " (u'LIWC_friend', 0.0),\n",
       " (u'min_phone_length', -0.11841505438139058),\n",
       " (u'LIWC_percept', 0.0),\n",
       " (u'the_business', 0.0),\n",
       " (u'LIWC_we', 0.0),\n",
       " (u'mean_pitch', -0.0),\n",
       " (u'back_in', 0.0),\n",
       " (u'internal_silence', 0.1178684567214011),\n",
       " (u'LIWC_power', 0.0),\n",
       " (u'will_be', 0.058892930007002173),\n",
       " (u'LIWC_i', 0.0),\n",
       " (u'of_this', 0.0),\n",
       " (u'country_to', 0.0),\n",
       " (u'rhyme', 0.0),\n",
       " (u'LIWC_auxverb', 0.0),\n",
       " (u'LIWC_focuspresent', 0.0),\n",
       " (u'a_commander', 0.0),\n",
       " (u'LIWC_motion', 0.077162140595016776),\n",
       " (u'in_the', 0.0),\n",
       " (u'LIWC_negate', 0.0),\n",
       " (u'rst_cat_N-purpose', 0.090784796912178556),\n",
       " (u'LIWC_achiev', 0.0),\n",
       " (u\"i_won't\", 0.0),\n",
       " (u'LIWC_female', 0.0),\n",
       " (u'the_military', 0.0),\n",
       " (u'get_back', 0.0),\n",
       " (u'LIWC_affiliation', 0.0),\n",
       " (u'out_there', 0.0),\n",
       " (u'a_lot', 0.11195111771020727),\n",
       " (u'will_have', 0.0),\n",
       " (u'to_act', 0.0),\n",
       " (u'LIWC_sexual', 0.0),\n",
       " (u'alliteration', 0.0),\n",
       " (u'who_will', 0.0),\n",
       " (u'LIWC_leisure', 0.0),\n",
       " (u'i_think', 0.0),\n",
       " (u'LIWC_reward', 0.0),\n",
       " (u'next_president', 0.0),\n",
       " (u'prepared_to', 0.0),\n",
       " (u'up_i', 0.19179859256822171),\n",
       " (u'the_next', 0.19939656953484275),\n",
       " (u'to_be', 0.0),\n",
       " (u'LIWC_focusfuture', 0.0),\n",
       " (u'have_the', 0.0),\n",
       " (u'a_big', 0.0),\n",
       " (u'in_chief', 0.0),\n",
       " (u'homogeneity', 0.0),\n",
       " (u'commander_in', 0.0),\n",
       " (u'this_country', 0.0)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeb_1_activations[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'be_a', 0.031838287462172883),\n",
       " (u'LIWC_friend', 0.033482519190737206),\n",
       " (u'min_phone_length', -0.11841505438139058),\n",
       " (u'LIWC_percept', 0.037158682089851985),\n",
       " (u'the_business', 0.047011592795904479),\n",
       " (u'LIWC_we', 0.047574463120682461),\n",
       " (u'mean_pitch', -0.081377825397440734),\n",
       " (u'back_in', 0.049425862091193665),\n",
       " (u'internal_silence', 0.1178684567214011),\n",
       " (u'LIWC_power', 0.05678676794291547),\n",
       " (u'will_be', 0.058892930007002173),\n",
       " (u'LIWC_i', 0.061607090604034916),\n",
       " (u'of_this', 0.066118407633243184),\n",
       " (u'country_to', 0.067722884021763075),\n",
       " (u'rhyme', 0.019610660860075655),\n",
       " (u'LIWC_auxverb', 0.072545241142137784),\n",
       " (u'LIWC_focuspresent', 0.075311245702706392),\n",
       " (u'a_commander', 0.076039724090637098),\n",
       " (u'LIWC_motion', 0.077162140595016776),\n",
       " (u'in_the', 0.07748078562768182),\n",
       " (u'LIWC_negate', 0.087615537447223946),\n",
       " (u'rst_cat_N-purpose', 0.090784796912178556),\n",
       " (u'LIWC_achiev', 0.092107404498263407),\n",
       " (u\"i_won't\", 0.094331942203364064),\n",
       " (u'LIWC_female', 0.097161055641983796),\n",
       " (u'the_military', 0.099201221547684945),\n",
       " (u'get_back', 0.1034745251250348),\n",
       " (u'LIWC_affiliation', 0.1051585605992003),\n",
       " (u'out_there', 0.10900533150938237),\n",
       " (u'a_lot', 0.11195111771020727),\n",
       " (u'will_have', 0.11330479827590878),\n",
       " (u'to_act', 0.11369581421713595),\n",
       " (u'LIWC_sexual', 0.11940543383397761),\n",
       " (u'alliteration', 0.029641535145655293),\n",
       " (u'who_will', 0.13029671481455618),\n",
       " (u'LIWC_leisure', 0.13945862338772833),\n",
       " (u'i_think', 0.15139069831578858),\n",
       " (u'LIWC_reward', 0.15658758837064971),\n",
       " (u'next_president', 0.16065333482330257),\n",
       " (u'prepared_to', 0.16085857712309032),\n",
       " (u'up_i', 0.19179859256822171),\n",
       " (u'the_next', 0.19939656953484275),\n",
       " (u'to_be', 0.23681158805542596),\n",
       " (u'LIWC_focusfuture', 0.23758315343147729),\n",
       " (u'have_the', 0.28289533599569761),\n",
       " (u'a_big', 0.34024417161966425),\n",
       " (u'in_chief', 0.35663012645851672),\n",
       " (u'homogeneity', 0.19740607627010645),\n",
       " (u'commander_in', 0.4043219032876767),\n",
       " (u'this_country', 0.46086127410673888)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeb_fails_features[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u\"So here's my pledge to you\", 0.24821266037726158),\n",
       " (u\"will be a commander in chief who will have the back of the military I won't trash talk I won't be a divider in chief or an agitator in chief I won't be out there blowharding talking a big game without backing it up I think the next President needs to be a lot quieter but send a signal that we're prepared to act in the national security interests of this country to get back in the business of creating a more peaceful world\",\n",
       "  0.9450858130262213),\n",
       " (u'Please clap', 0.39974463627379864)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(jeb.alignment.get_phrase_text(), model.predict_proba(jeb_train)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = featurizer.Featurizer(s)\n",
    "#feature_set = ['audio','liu','euphony','phone','cosine','substring','word_overlap','rst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_delta(feature_names):\n",
    "    return [\"delta_\"+f for f in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_feature_names = feat.get_audio_feature_names() + make_delta(feat.get_audio_feature_names()) + feat.get_liu_feature_names() + make_delta(feat.get_liu_feature_names()) + feat.get_euphony_feature_names() + make_delta(feat.get_euphony_feature_names()) + feat.get_phone_feature_names() + make_delta(feat.get_phone_feature_names())+feat.get_cosine_feature_names() + make_delta(feat.get_cosine_feature_names())+feat.get_substring_feature_names() + make_delta(feat.get_substring_feature_names())+ feat.get_word_overlap_feature_names() + make_delta(feat.get_word_overlap_feature_names())+feat.get_rst_feature_names() + make_delta(feat.get_rst_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_feature_names = all_bigram_names + feat.get_audio_feature_names()+ feat.get_liu_feature_names() + feat.get_euphony_feature_names() + feat.get_phone_feature_names() + feat.get_cosine_feature_names() +feat.get_substring_feature_names() + feat.get_word_overlap_feature_names() +feat.get_rst_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/corpora/cspan/top_bigrams.pkl','rb') as f:\n",
    "    top_bigrams = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_bigram_names = [n[0] for n in top_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_bigram_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'000_50',\n",
       " u'000_70',\n",
       " u'000_a',\n",
       " u'000_e',\n",
       " u'000_factories',\n",
       " u'000_in',\n",
       " u'000_jobs',\n",
       " u'000_or',\n",
       " u'000_people',\n",
       " u'000_soldiers']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bigram_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef_list = zip(np.array(all_feature_names)[np.argsort(coefs)],coefs[np.argsort(coefs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/jrgillick/coef_list.txt','wb') as f:\n",
    "    for c in coef_list:\n",
    "        f.write(str(c[0]) + ' ' + str(c[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'speech' from 'speech.pyc'>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speechjeb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talk_about -0.566926635654'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(coef_list[0][0]) + ' ' + str(coef_list[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = speech.Speech('bernie_sanders_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_logistic_cross_validation(feature_set, phrase_count):\n",
    "    all_true = []; all_pred = []\n",
    "    C = 0.1\n",
    "    for speaker in speaker_names:\n",
    "        print speaker + \": \"\n",
    "        train_set, test_set = get_train_and_test_sets(speaker)\n",
    "\n",
    "        labels_train = get_labels(train_set)\n",
    "        data_train = get_features(train_set,feature_set)\n",
    "\n",
    "        labels_test = get_labels(test_set)\n",
    "        data_test = get_features(test_set,feature_set)\n",
    "\n",
    "        current_train_formatted_feats, current_train_formatted_labs = models.format_balanced_multiple_phrase_input(data_train,labels_train,phrase_count=phrase_count)\n",
    "        current_test_formatted_feats, current_test_formatted_labs = models.format_balanced_multiple_phrase_input(data_test,labels_test,phrase_count=phrase_count)\n",
    "\n",
    "        X_train = np.array(current_train_formatted_feats).astype('float64')\n",
    "        y_train = np.array(current_train_formatted_labs)\n",
    "        \n",
    "        print X_train.shape\n",
    "\n",
    "        X_test = np.array(current_test_formatted_feats).astype('float64')\n",
    "        y_test = np.array(current_test_formatted_labs)\n",
    "\n",
    "        X_train, X_test = normalize_data(X_train,X_test)\n",
    "        if C is None:\n",
    "            model = models.train_cv_logistic_regression_faster(X_train,y_train)\n",
    "            C = model.best_params_['C']\n",
    "        else:\n",
    "            model = models.train_logistic_regression(X_train,y_train,C)\n",
    "        y_true, y_pred = models.evaluate_model(model, X_test, y_test)\n",
    "        \n",
    "        all_true += list(y_true)\n",
    "        all_pred += list(y_pred)\n",
    "        print\n",
    "    return all_true, all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_logistic_single_speaker(feature_set, phrase_count):\n",
    "    all_true = []; all_pred = []\n",
    "    C = None\n",
    "    for speaker in speaker_names:\n",
    "        print speaker + \": \"\n",
    "        other, speaker_data = get_train_and_test_sets(speaker)\n",
    "        speaker_data = np.array(speaker_data)\n",
    "        #speaker_labels = get_labels(speaker_data)\n",
    "        \n",
    "        if len(speaker_data) == 1:\n",
    "            continue\n",
    "        \n",
    "        if len(speaker_data) > 10:\n",
    "            kf = KFold(n_splits=10)\n",
    "        else:\n",
    "            kf = KFold(n_splits=len(speaker_data))\n",
    "            \n",
    "        for train_index, test_index in kf.split(speaker_data):\n",
    "            train_set = speaker_data[train_index]\n",
    "            test_set = speaker_data[test_index]\n",
    "            #train_set, test_set = train_test_split(speaker_data, test_size=0.2, random_state=43)\n",
    "\n",
    "            labels_train = get_labels(train_set)\n",
    "            data_train = get_features(train_set,feature_set)\n",
    "\n",
    "            labels_test = get_labels(test_set)\n",
    "            data_test = get_features(test_set,feature_set)\n",
    "\n",
    "            current_train_formatted_feats, current_train_formatted_labs = models.format_balanced_multiple_phrase_input(data_train,labels_train,phrase_count=phrase_count)\n",
    "            current_test_formatted_feats, current_test_formatted_labs = models.format_balanced_multiple_phrase_input(data_test,labels_test,phrase_count=phrase_count)\n",
    "\n",
    "            X_train = np.array(current_train_formatted_feats).astype('float64')\n",
    "            y_train = np.array(current_train_formatted_labs)\n",
    "\n",
    "            X_test = np.array(current_test_formatted_feats).astype('float64')\n",
    "            y_test = np.array(current_test_formatted_labs)\n",
    "\n",
    "            #print X_train.shape\n",
    "            #print X_test.shape\n",
    "\n",
    "            if len(y_train) > 0 and len(y_test) > 0:\n",
    "\n",
    "                X_train, X_test = normalize_data(X_train,X_test)\n",
    "                if C is None and len(y_train) > 500:\n",
    "                    model = models.train_cv_logistic_regression_faster(X_train,y_train)\n",
    "                    C = model.best_params_['C']\n",
    "                else:\n",
    "                    model = models.train_logistic_regression(X_train,y_train)\n",
    "                y_true, y_pred = models.evaluate_model(model, X_test, y_test)\n",
    "                \n",
    "                all_true += list(y_true)\n",
    "                all_pred += list(y_pred)\n",
    "                \n",
    "                #print len(all_true)\n",
    "            print\n",
    "    #print len(all_true)\n",
    "    #print len(all_pred)\n",
    "    return all_true, all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_logistic_single_speaker_n_gram_and_deltas(feature_set, phrase_count):\n",
    "    feature_set.remove('bigrams')\n",
    "    all_true = []; all_pred = []\n",
    "    C = None\n",
    "    for speaker in speaker_names:\n",
    "        print speaker + \": \"\n",
    "        other, speaker_data = get_train_and_test_sets(speaker)\n",
    "        speaker_data = np.array(speaker_data)\n",
    "        #speaker_labels = get_labels(speaker_data)\n",
    "        \n",
    "        if len(speaker_data) == 1:\n",
    "            continue\n",
    "        \n",
    "        if len(speaker_data) > 10:\n",
    "            kf = KFold(n_splits=10)\n",
    "        else:\n",
    "            kf = KFold(n_splits=len(speaker_data))\n",
    "            \n",
    "        for train_index, test_index in kf.split(speaker_data):\n",
    "            train_set = speaker_data[train_index]\n",
    "            test_set = speaker_data[test_index]\n",
    "            #train_set, test_set = train_test_split(speaker_data, test_size=0.2, random_state=43)\n",
    "\n",
    "            labels_train = get_labels(train_set)\n",
    "            data_train = get_features(train_set,feature_set)\n",
    "            \n",
    "            n_grams_train = get_features(train_set,['bigrams'])\n",
    "\n",
    "            labels_test = get_labels(test_set)\n",
    "            data_test = get_features(test_set,feature_set)\n",
    "            n_grams_test = get_features(test_set,['bigrams'])\n",
    "\n",
    "            current_train_formatted_feats, current_train_formatted_labs = models.format_balanced_multiple_phrase_input_with_deltas(data_train,labels_train,phrase_count=phrase_count)\n",
    "            current_test_formatted_feats, current_test_formatted_labs = models.format_balanced_multiple_phrase_input_with_deltas(data_test,labels_test,phrase_count=phrase_count)\n",
    "\n",
    "            train_ngram_formatted_feats, current_train_formatted_labs = models.format_balanced_multiple_phrase_input(n_grams_train,labels_train,phrase_count=1)\n",
    "            test_ngram_formatted_feats, current_test_formatted_labs = models.format_balanced_multiple_phrase_input(n_grams_test,labels_test,phrase_count=1)\n",
    "\n",
    "            \n",
    "            X_train = np.array(current_train_formatted_feats).astype('float64')\n",
    "            y_train = np.array(current_train_formatted_labs)\n",
    "            \n",
    "            X_train_2 = np.array(train_ngram_formatted_feats).astype('float64')\n",
    "\n",
    "            X_test = np.array(current_test_formatted_feats).astype('float64')\n",
    "            y_test = np.array(current_test_formatted_labs)\n",
    "            \n",
    "            X_test_2 = np.array(test_ngram_formatted_feats).astype('float64')\n",
    "\n",
    "            print X_train.shape\n",
    "            print X_train_2.shape\n",
    "            print X_test.shape\n",
    "            print X_test_2.shape\n",
    "            \n",
    "            X_train = np.hstack([X_train,X_train_2])\n",
    "            X_test = np.hstack([X_test,X_test_2])\n",
    "\n",
    "            if len(y_train) > 0 and len(y_test) > 0:\n",
    "\n",
    "                X_train, X_test = normalize_data(X_train,X_test)\n",
    "                if C is None and len(y_train) > 500:\n",
    "                    model = models.train_cv_logistic_regression_faster(X_train,y_train)\n",
    "                    C = model.best_params_['C']\n",
    "                else:\n",
    "                    model = models.train_logistic_regression(X_train,y_train)\n",
    "                y_true, y_pred = models.evaluate_model(model, X_test, y_test)\n",
    "                \n",
    "                all_true += list(y_true)\n",
    "                all_pred += list(y_pred)\n",
    "                \n",
    "                #print len(all_true)\n",
    "            print\n",
    "    #print len(all_true)\n",
    "    #print len(all_pred)\n",
    "    return all_true, all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_true, all_pred = run_logistic_single_speaker_n_gram_and_deltas(['bigrams','audio','liu','euphony','phone','cosine','substring','word_overlap','rst'],phrase_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald_trump: \n",
      "(22678, 26704)\n",
      "Accuracy: 0.575 +/- 0.009 (7387/12846) | Precision: 0.626 | Recall: 0.373 | F1: 0.467\n",
      "\n",
      "hilary_clinton: \n",
      "(28264, 26704)\n",
      "Accuracy: 0.612 +/- 0.011 (4440/7260) | Precision: 0.645 | Recall: 0.497 | F1: 0.561\n",
      "\n",
      "bernie_sanders: \n",
      "(29006, 26704)\n",
      "Accuracy: 0.628 +/- 0.012 (4092/6518) | Precision: 0.677 | Recall: 0.489 | F1: 0.568\n",
      "\n",
      "ted_cruz: \n",
      "(33442, 26704)\n",
      "Accuracy: 0.626 +/- 0.021 (1304/2082) | Precision: 0.684 | Recall: 0.469 | F1: 0.556\n",
      "\n",
      "marco_rubio: \n",
      "(33938, 26704)\n",
      "Accuracy: 0.627 +/- 0.024 (994/1586) | Precision: 0.658 | Recall: 0.528 | F1: 0.586\n",
      "\n",
      "john_kasich: \n",
      "(34886, 26704)\n",
      "Accuracy: 0.630 +/- 0.037 (402/638) | Precision: 0.706 | Recall: 0.445 | F1: 0.546\n",
      "\n",
      "barack_obama: \n",
      "(33684, 26704)\n",
      "Accuracy: 0.559 +/- 0.023 (1028/1840) | Precision: 0.624 | Recall: 0.296 | F1: 0.401\n",
      "\n",
      "bill_clinton: \n",
      "(34940, 26704)\n",
      "Accuracy: 0.596 +/- 0.040 (348/584) | Precision: 0.665 | Recall: 0.387 | F1: 0.489\n",
      "\n",
      "joe_biden: \n",
      "(34984, 26704)\n",
      "Accuracy: 0.615 +/- 0.041 (332/540) | Precision: 0.687 | Recall: 0.422 | F1: 0.523\n",
      "\n",
      "mike_pence: \n",
      "(35032, 26704)\n",
      "Accuracy: 0.638 +/- 0.042 (314/492) | Precision: 0.702 | Recall: 0.480 | F1: 0.570\n",
      "\n",
      "carly_fiorina: \n",
      "(35266, 26704)\n",
      "Accuracy: 0.632 +/- 0.059 (163/258) | Precision: 0.660 | Recall: 0.543 | F1: 0.596\n",
      "\n",
      "jeb_bush: \n",
      "(35142, 26704)\n",
      "Accuracy: 0.589 +/- 0.049 (225/382) | Precision: 0.629 | Recall: 0.435 | F1: 0.514\n",
      "\n",
      "rand_paul: \n",
      "(35256, 26704)\n",
      "Accuracy: 0.649 +/- 0.057 (174/268) | Precision: 0.682 | Recall: 0.560 | F1: 0.615\n",
      "\n",
      "gary_johnson: \n",
      "(35412, 26704)\n",
      "Accuracy: 0.518 +/- 0.093 (58/112) | Precision: 0.525 | Recall: 0.375 | F1: 0.438\n",
      "\n",
      "chris_christie: \n",
      "(35440, 26704)\n",
      "Accuracy: 0.571 +/- 0.106 (48/84) | Precision: 0.625 | Recall: 0.357 | F1: 0.455\n",
      "\n",
      "rick_santorum: \n",
      "(35490, 26704)\n",
      "Accuracy: 0.559 +/- 0.167 (19/34) | Precision: 0.571 | Recall: 0.471 | F1: 0.516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_true,all_pred = run_logistic_cross_validation(['bigrams'],phrase_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_correct_n_gram = 7387 + 4440 + 4092 + 1304 + 994 + 402 + 1028 + 348 + 332 + 314 + 163 + 174+58+48+19\n",
    "over_n_gram = 12846 + 7260 + 6518 + 2082 + 1586 + 638 + 1840 + 584 + 540 + 492 + 258 + 382 + 268 + 112 + 84 + 34\n",
    "acc_here = float(total_correct_n_gram) / over_n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5940490935705438"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald_trump: \n",
      "Accuracy: 0.650 +/- 0.022 (1210/1862) | Precision: 0.674 | Recall: 0.581 | F1: 0.624\n",
      "\n",
      "Accuracy: 0.664 +/- 0.028 (752/1132) | Precision: 0.689 | Recall: 0.599 | F1: 0.641\n",
      "\n",
      "Accuracy: 0.674 +/- 0.027 (781/1158) | Precision: 0.705 | Recall: 0.599 | F1: 0.648\n",
      "\n",
      "Accuracy: 0.664 +/- 0.027 (756/1138) | Precision: 0.679 | Recall: 0.622 | F1: 0.650\n",
      "\n",
      "Accuracy: 0.676 +/- 0.022 (1143/1692) | Precision: 0.684 | Recall: 0.651 | F1: 0.667\n",
      "\n",
      "Accuracy: 0.640 +/- 0.023 (1108/1730) | Precision: 0.664 | Recall: 0.568 | F1: 0.612\n",
      "\n",
      "Accuracy: 0.657 +/- 0.027 (796/1212) | Precision: 0.666 | Recall: 0.630 | F1: 0.647\n",
      "\n",
      "Accuracy: 0.688 +/- 0.033 (523/760) | Precision: 0.698 | Recall: 0.663 | F1: 0.680\n",
      "\n",
      "Accuracy: 0.642 +/- 0.026 (860/1340) | Precision: 0.649 | Recall: 0.618 | F1: 0.633\n",
      "\n",
      "Accuracy: 0.676 +/- 0.032 (556/822) | Precision: 0.693 | Recall: 0.633 | F1: 0.662\n",
      "\n",
      "hilary_clinton: \n",
      "Accuracy: 0.689 +/- 0.033 (528/766) | Precision: 0.677 | Recall: 0.723 | F1: 0.699\n",
      "\n",
      "Accuracy: 0.700 +/- 0.035 (466/666) | Precision: 0.721 | Recall: 0.652 | F1: 0.685\n",
      "\n",
      "Accuracy: 0.690 +/- 0.039 (370/536) | Precision: 0.713 | Recall: 0.638 | F1: 0.673\n",
      "\n",
      "Accuracy: 0.696 +/- 0.033 (518/744) | Precision: 0.723 | Recall: 0.637 | F1: 0.677\n",
      "\n",
      "Accuracy: 0.726 +/- 0.031 (566/780) | Precision: 0.744 | Recall: 0.687 | F1: 0.715\n",
      "\n",
      "Accuracy: 0.691 +/- 0.038 (384/556) | Precision: 0.717 | Recall: 0.629 | F1: 0.670\n",
      "\n",
      "Accuracy: 0.652 +/- 0.028 (732/1122) | Precision: 0.656 | Recall: 0.640 | F1: 0.648\n",
      "\n",
      "Accuracy: 0.696 +/- 0.033 (529/760) | Precision: 0.721 | Recall: 0.639 | F1: 0.678\n",
      "\n",
      "Accuracy: 0.689 +/- 0.034 (478/694) | Precision: 0.692 | Recall: 0.680 | F1: 0.686\n",
      "\n",
      "Accuracy: 0.679 +/- 0.036 (432/636) | Precision: 0.693 | Recall: 0.645 | F1: 0.668\n",
      "\n",
      "bernie_sanders: \n",
      "Accuracy: 0.720 +/- 0.031 (593/824) | Precision: 0.747 | Recall: 0.665 | F1: 0.703\n",
      "\n",
      "Accuracy: 0.695 +/- 0.042 (324/466) | Precision: 0.714 | Recall: 0.652 | F1: 0.682\n",
      "\n",
      "Accuracy: 0.739 +/- 0.043 (300/406) | Precision: 0.746 | Recall: 0.724 | F1: 0.735\n",
      "\n",
      "Accuracy: 0.724 +/- 0.029 (640/884) | Precision: 0.720 | Recall: 0.733 | F1: 0.726\n",
      "\n",
      "Accuracy: 0.680 +/- 0.042 (317/466) | Precision: 0.706 | Recall: 0.618 | F1: 0.659\n",
      "\n",
      "Accuracy: 0.720 +/- 0.030 (635/882) | Precision: 0.724 | Recall: 0.712 | F1: 0.718\n",
      "\n",
      "Accuracy: 0.727 +/- 0.047 (253/348) | Precision: 0.734 | Recall: 0.713 | F1: 0.723\n",
      "\n",
      "Accuracy: 0.736 +/- 0.035 (461/626) | Precision: 0.745 | Recall: 0.719 | F1: 0.732\n",
      "\n",
      "Accuracy: 0.723 +/- 0.031 (574/794) | Precision: 0.726 | Recall: 0.715 | F1: 0.721\n",
      "\n",
      "Accuracy: 0.717 +/- 0.031 (589/822) | Precision: 0.711 | Recall: 0.730 | F1: 0.720\n",
      "\n",
      "ted_cruz: \n",
      "Accuracy: 0.631 +/- 0.059 (164/260) | Precision: 0.660 | Recall: 0.538 | F1: 0.593\n",
      "\n",
      "Accuracy: 0.654 +/- 0.069 (119/182) | Precision: 0.667 | Recall: 0.615 | F1: 0.640\n",
      "\n",
      "Accuracy: 0.696 +/- 0.051 (220/316) | Precision: 0.725 | Recall: 0.633 | F1: 0.676\n",
      "\n",
      "Accuracy: 0.625 +/- 0.066 (130/208) | Precision: 0.662 | Recall: 0.510 | F1: 0.576\n",
      "\n",
      "Accuracy: 0.746 +/- 0.080 (85/114) | Precision: 0.719 | Recall: 0.807 | F1: 0.760\n",
      "\n",
      "Accuracy: 0.761 +/- 0.062 (137/180) | Precision: 0.783 | Recall: 0.722 | F1: 0.751\n",
      "\n",
      "Accuracy: 0.649 +/- 0.062 (148/228) | Precision: 0.673 | Recall: 0.579 | F1: 0.623\n",
      "\n",
      "Accuracy: 0.654 +/- 0.068 (123/188) | Precision: 0.679 | Recall: 0.585 | F1: 0.629\n",
      "\n",
      "Accuracy: 0.674 +/- 0.055 (186/276) | Precision: 0.694 | Recall: 0.623 | F1: 0.656\n",
      "\n",
      "Accuracy: 0.669 +/- 0.081 (87/130) | Precision: 0.696 | Recall: 0.600 | F1: 0.645\n",
      "\n",
      "marco_rubio: \n",
      "Accuracy: 0.572 +/- 0.063 (135/236) | Precision: 0.600 | Recall: 0.432 | F1: 0.502\n",
      "\n",
      "Accuracy: 0.480 +/- 0.070 (94/196) | Precision: 0.484 | Recall: 0.602 | F1: 0.536\n",
      "\n",
      "Accuracy: 0.596 +/- 0.082 (81/136) | Precision: 0.659 | Recall: 0.397 | F1: 0.495\n",
      "\n",
      "Accuracy: 0.648 +/- 0.079 (92/142) | Precision: 0.627 | Recall: 0.732 | F1: 0.675\n",
      "\n",
      "Accuracy: 0.672 +/- 0.056 (184/274) | Precision: 0.697 | Recall: 0.606 | F1: 0.648\n",
      "\n",
      "Accuracy: 0.630 +/- 0.129 (34/54) | Precision: 0.640 | Recall: 0.593 | F1: 0.615\n",
      "\n",
      "Accuracy: 0.617 +/- 0.069 (116/188) | Precision: 0.631 | Recall: 0.564 | F1: 0.596\n",
      "\n",
      "Accuracy: 0.669 +/- 0.072 (111/166) | Precision: 0.706 | Recall: 0.578 | F1: 0.636\n",
      "\n",
      "Accuracy: 0.736 +/- 0.102 (53/72) | Precision: 0.718 | Recall: 0.778 | F1: 0.747\n",
      "\n",
      "Accuracy: 0.598 +/- 0.087 (73/122) | Precision: 0.577 | Recall: 0.738 | F1: 0.647\n",
      "\n",
      "john_kasich: \n",
      "Accuracy: 0.800 +/- 0.124 (32/40) | Precision: 0.875 | Recall: 0.700 | F1: 0.778\n",
      "\n",
      "Accuracy: 0.561 +/- 0.107 (46/82) | Precision: 0.541 | Recall: 0.805 | F1: 0.647\n",
      "\n",
      "Accuracy: 0.619 +/- 0.104 (52/84) | Precision: 0.679 | Recall: 0.452 | F1: 0.543\n",
      "\n",
      "Accuracy: 0.595 +/- 0.112 (44/74) | Precision: 0.581 | Recall: 0.676 | F1: 0.625\n",
      "\n",
      "Accuracy: 0.614 +/- 0.102 (54/88) | Precision: 0.619 | Recall: 0.591 | F1: 0.605\n",
      "\n",
      "Accuracy: 0.759 +/- 0.081 (82/108) | Precision: 0.833 | Recall: 0.648 | F1: 0.729\n",
      "\n",
      "Accuracy: 0.654 +/- 0.129 (34/52) | Precision: 0.750 | Recall: 0.462 | F1: 0.571\n",
      "\n",
      "Accuracy: 0.500 +/- 0.192 (13/26) | Precision: 0.500 | Recall: 0.692 | F1: 0.581\n",
      "\n",
      "Accuracy: 0.900 +/- 0.131 (18/20) | Precision: 0.900 | Recall: 0.900 | F1: 0.900\n",
      "\n",
      "Accuracy: 0.734 +/- 0.108 (47/64) | Precision: 0.742 | Recall: 0.719 | F1: 0.730\n",
      "\n",
      "barack_obama: \n",
      "Accuracy: 0.618 +/- 0.077 (94/152) | Precision: 0.610 | Recall: 0.658 | F1: 0.633\n",
      "\n",
      "Accuracy: 0.694 +/- 0.046 (272/392) | Precision: 0.692 | Recall: 0.699 | F1: 0.695\n",
      "\n",
      "Accuracy: 0.629 +/- 0.088 (73/116) | Precision: 0.692 | Recall: 0.466 | F1: 0.557\n",
      "\n",
      "Accuracy: 0.689 +/- 0.061 (153/222) | Precision: 0.684 | Recall: 0.703 | F1: 0.693\n",
      "\n",
      "Accuracy: 0.637 +/- 0.052 (209/328) | Precision: 0.630 | Recall: 0.665 | F1: 0.647\n",
      "\n",
      "Accuracy: 0.645 +/- 0.080 (89/138) | Precision: 0.727 | Recall: 0.464 | F1: 0.566\n",
      "\n",
      "Accuracy: 0.682 +/- 0.070 (116/170) | Precision: 0.738 | Recall: 0.565 | F1: 0.640\n",
      "\n",
      "Accuracy: 0.684 +/- 0.065 (134/196) | Precision: 0.737 | Recall: 0.571 | F1: 0.644\n",
      "\n",
      "Accuracy: 0.647 +/- 0.161 (22/34) | Precision: 0.778 | Recall: 0.412 | F1: 0.538\n",
      "\n",
      "Accuracy: 0.663 +/- 0.097 (61/92) | Precision: 0.636 | Recall: 0.761 | F1: 0.693\n",
      "\n",
      "bill_clinton: \n",
      "Accuracy: 0.625 +/- 0.127 (35/56) | Precision: 0.652 | Recall: 0.536 | F1: 0.588\n",
      "\n",
      "Accuracy: 0.625 +/- 0.137 (30/48) | Precision: 0.625 | Recall: 0.625 | F1: 0.625\n",
      "\n",
      "Accuracy: 0.455 +/- 0.208 (10/22) | Precision: 0.444 | Recall: 0.364 | F1: 0.400\n",
      "\n",
      "Accuracy: 0.595 +/- 0.070 (113/190) | Precision: 0.598 | Recall: 0.579 | F1: 0.588\n",
      "\n",
      "Accuracy: 0.629 +/- 0.120 (39/62) | Precision: 0.618 | Recall: 0.677 | F1: 0.646\n",
      "\n",
      "Accuracy: 0.556 +/- 0.230 (10/18) | Precision: 0.556 | Recall: 0.556 | F1: 0.556\n",
      "\n",
      "Accuracy: 0.650 +/- 0.079 (91/140) | Precision: 0.678 | Recall: 0.571 | F1: 0.620\n",
      "\n",
      "Accuracy: 0.646 +/- 0.135 (31/48) | Precision: 0.600 | Recall: 0.875 | F1: 0.712\n",
      "\n",
      "joe_biden: \n",
      "Accuracy: 0.537 +/- 0.133 (29/54) | Precision: 0.542 | Recall: 0.481 | F1: 0.510\n",
      "\n",
      "Accuracy: 0.580 +/- 0.066 (123/212) | Precision: 0.620 | Recall: 0.415 | F1: 0.497\n",
      "\n",
      "\n",
      "\n",
      "Accuracy: 0.598 +/- 0.100 (55/92) | Precision: 0.610 | Recall: 0.543 | F1: 0.575\n",
      "\n",
      "Accuracy: 0.517 +/- 0.126 (31/60) | Precision: 0.519 | Recall: 0.467 | F1: 0.491\n",
      "\n",
      "Accuracy: 0.656 +/- 0.084 (80/122) | Precision: 0.651 | Recall: 0.672 | F1: 0.661\n",
      "\n",
      "mike_pence: \n",
      "Accuracy: 0.662 +/- 0.104 (53/80) | Precision: 0.600 | Recall: 0.975 | F1: 0.743\n",
      "\n",
      "Accuracy: 0.556 +/- 0.087 (70/126) | Precision: 0.543 | Recall: 0.698 | F1: 0.611\n",
      "\n",
      "Accuracy: 0.689 +/- 0.096 (62/90) | Precision: 0.707 | Recall: 0.644 | F1: 0.674\n",
      "\n",
      "Accuracy: 1.000 +/- 0.000 (8/8) | Precision: 1.000 | Recall: 1.000 | F1: 1.000\n",
      "\n",
      "Accuracy: 0.714 +/- 0.097 (60/84) | Precision: 0.765 | Recall: 0.619 | F1: 0.684\n",
      "\n",
      "Accuracy: 0.654 +/- 0.091 (68/104) | Precision: 0.711 | Recall: 0.519 | F1: 0.600\n",
      "\n",
      "carly_fiorina: \n",
      "Accuracy: 0.550 +/- 0.154 (22/40) | Precision: 0.542 | Recall: 0.650 | F1: 0.591\n",
      "\n",
      "Accuracy: 0.517 +/- 0.129 (30/58) | Precision: 0.513 | Recall: 0.690 | F1: 0.588\n",
      "\n",
      "Accuracy: 0.484 +/- 0.124 (30/62) | Precision: 0.474 | Recall: 0.290 | F1: 0.360\n",
      "\n",
      "Accuracy: 0.487 +/- 0.111 (38/78) | Precision: 0.488 | Recall: 0.513 | F1: 0.500\n",
      "\n",
      "Accuracy: 0.600 +/- 0.215 (12/20) | Precision: 0.571 | Recall: 0.800 | F1: 0.667\n",
      "\n",
      "jeb_bush: \n",
      "Accuracy: 0.630 +/- 0.067 (126/200) | Precision: 0.651 | Recall: 0.560 | F1: 0.602\n",
      "\n",
      "Accuracy: 0.566 +/- 0.111 (43/76) | Precision: 0.647 | Recall: 0.289 | F1: 0.400\n",
      "\n",
      "Accuracy: 0.656 +/- 0.165 (21/32) | Precision: 0.647 | Recall: 0.688 | F1: 0.667\n",
      "\n",
      "Accuracy: 0.641 +/- 0.118 (41/64) | Precision: 0.629 | Recall: 0.688 | F1: 0.657\n",
      "\n",
      "Accuracy: 0.600 +/- 0.304 (6/10) | Precision: 0.667 | Recall: 0.400 | F1: 0.500\n",
      "\n",
      "rand_paul: \n",
      "Accuracy: 0.629 +/- 0.120 (39/62) | Precision: 0.600 | Recall: 0.774 | F1: 0.676\n",
      "\n",
      "Accuracy: 0.516 +/- 0.124 (32/62) | Precision: 0.522 | Recall: 0.387 | F1: 0.444\n",
      "\n",
      "Accuracy: 0.500 +/- 0.693 (1/2) | Precision: 0.500 | Recall: 1.000 | F1: 0.667\n",
      "\n",
      "Accuracy: 0.620 +/- 0.080 (88/142) | Precision: 0.644 | Recall: 0.535 | F1: 0.585\n",
      "\n",
      "gary_johnson: \n",
      "Accuracy: 0.346 +/- 0.183 (9/26) | Precision: 0.389 | Recall: 0.538 | F1: 0.452\n",
      "\n",
      "Accuracy: 0.625 +/- 0.237 (10/16) | Precision: 0.750 | Recall: 0.375 | F1: 0.500\n",
      "\n",
      "Accuracy: 0.443 +/- 0.116 (31/70) | Precision: 0.447 | Recall: 0.486 | F1: 0.466\n",
      "\n",
      "chris_christie: \n",
      "Accuracy: 0.700 +/- 0.201 (14/20) | Precision: 0.700 | Recall: 0.700 | F1: 0.700\n",
      "\n",
      "Accuracy: 0.588 +/- 0.165 (20/34) | Precision: 0.560 | Recall: 0.824 | F1: 0.667\n",
      "\n",
      "Accuracy: 0.533 +/- 0.179 (16/30) | Precision: 0.556 | Recall: 0.333 | F1: 0.417\n",
      "\n",
      "rick_santorum: \n"
     ]
    }
   ],
   "source": [
    "all_true,all_pred = run_logistic_single_speaker(['bigrams','audio','liu','euphony','phone','cosine','substring','word_overlap','rst'],phrase_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_correct = 1210+752+781+756+1143+1108+796+523+860+556\n",
    "trump_total = 1862+1132+1158+1138+1692+1730+1212+760+1340+822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald_trump: \n",
      "(22678, 155)\n",
      "Accuracy: 0.588 +/- 0.009 (7559/12846) | Precision: 0.600 | Recall: 0.531 | F1: 0.563\n",
      "\n",
      "hilary_clinton: \n",
      "(28264, 155)\n",
      "Accuracy: 0.658 +/- 0.011 (4774/7260) | Precision: 0.653 | Recall: 0.674 | F1: 0.663\n",
      "\n",
      "bernie_sanders: \n",
      "(29006, 155)\n",
      "Accuracy: 0.616 +/- 0.012 (4017/6518) | Precision: 0.637 | Recall: 0.542 | F1: 0.586\n",
      "\n",
      "ted_cruz: \n",
      "(33442, 155)\n",
      "Accuracy: 0.632 +/- 0.021 (1315/2082) | Precision: 0.659 | Recall: 0.545 | F1: 0.597\n",
      "\n",
      "marco_rubio: \n",
      "(33938, 155)\n",
      "Accuracy: 0.637 +/- 0.024 (1011/1586) | Precision: 0.639 | Recall: 0.631 | F1: 0.635\n",
      "\n",
      "john_kasich: \n",
      "(34886, 155)\n",
      "Accuracy: 0.672 +/- 0.036 (429/638) | Precision: 0.688 | Recall: 0.630 | F1: 0.658\n",
      "\n",
      "barack_obama: \n",
      "(33684, 155)\n",
      "Accuracy: 0.637 +/- 0.022 (1173/1840) | Precision: 0.655 | Recall: 0.582 | F1: 0.616\n",
      "\n",
      "bill_clinton: \n",
      "(34940, 155)\n",
      "Accuracy: 0.625 +/- 0.039 (365/584) | Precision: 0.629 | Recall: 0.610 | F1: 0.619\n",
      "\n",
      "joe_biden: \n",
      "(34984, 155)\n",
      "Accuracy: 0.617 +/- 0.041 (333/540) | Precision: 0.618 | Recall: 0.611 | F1: 0.615\n",
      "\n",
      "mike_pence: \n",
      "(35032, 155)\n",
      "Accuracy: 0.654 +/- 0.042 (322/492) | Precision: 0.648 | Recall: 0.675 | F1: 0.661\n",
      "\n",
      "carly_fiorina: \n",
      "(35266, 155)\n",
      "Accuracy: 0.597 +/- 0.060 (154/258) | Precision: 0.578 | Recall: 0.721 | F1: 0.641\n",
      "\n",
      "jeb_bush: \n",
      "(35142, 155)\n",
      "Accuracy: 0.654 +/- 0.048 (250/382) | Precision: 0.695 | Recall: 0.550 | F1: 0.614\n",
      "\n",
      "rand_paul: \n",
      "(35256, 155)\n",
      "Accuracy: 0.646 +/- 0.057 (173/268) | Precision: 0.626 | Recall: 0.724 | F1: 0.671\n",
      "\n",
      "gary_johnson: \n",
      "(35412, 155)\n",
      "Accuracy: 0.598 +/- 0.091 (67/112) | Precision: 0.608 | Recall: 0.554 | F1: 0.579\n",
      "\n",
      "chris_christie: \n",
      "(35440, 155)\n",
      "Accuracy: 0.619 +/- 0.104 (52/84) | Precision: 0.632 | Recall: 0.571 | F1: 0.600\n",
      "\n",
      "rick_santorum: \n",
      "(35490, 155)\n",
      "Accuracy: 0.500 +/- 0.168 (17/34) | Precision: 0.500 | Recall: 0.471 | F1: 0.485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_true,all_pred = run_logistic_cross_validation(['audio','liu','euphony','phone','cosine','substring','word_overlap','rst'],phrase_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.668 +/- 0.005 (23740/35524) | Precision: 0.650 | Recall: 0.435 | F1: 0.521\n"
     ]
    }
   ],
   "source": [
    "#total_correct = np.sum(np.array(all_true) == np.array(all_pred))\n",
    "acc=float(total_correct) / len(all_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(all_true) )\n",
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(all_true, all_pred)]\n",
    "print \"Accuracy: %.3f +/- %.3f (%s/%s) | Precision: %.3f | Recall: %.3f | F1: %.3f\" % (acc, 1.96*std, total_correct, len(all_true), precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6689208227669766"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct = 1171 + 748 + 767 + 756 + 1135 + 1101 + 794 + 522 + 868 + 571+ 528 + 465 + 381 + 506 + 563 + 539 + 741 + 497 + 470 + 421 + 584 + 341 + 294 + 615 + 321 + 619 + 249 + 475 + 571+ 586 + 178 + 118 + 195+135 +81 + 126 + 154 + 127 + 174 + 95+130 + 115+ 84 + 93 + 174 + 39 + 118 + 118 + 51 + 69 + 31 + 49 + 58 + 51 + 59 + 78 + 33 + 11 + 15 + 35 + 98 + 245 + 81 + 161 + 197 + 77 + 110 + 129 + 21 + 57 + 30 + 28 + 13 + 116 + 40 + 11 + 91 + 29 + 32 + 115+ 60 + 25 + 84 + 50 + 71 + 52+ 5+57 + 65 + 24 + 25 + 34 + 40 + 9 + 124 + 44 + 15 + 34 + 4 + 31 + 33 + 1 + 75 + 16 + 8 + 37 + 14 + 14 + 15\n",
    "total_predicted = 1862 + 1132 + 1158 + 1138 + 1692 + 1730 + 1212 + 760 + 1340 + 822 + 766+ 666+536 + 744+780 +556 + 1122 + 760 + 694 + 636 + 824 + 466 + 406 + 884 + 466 + 882 + 348 + 626 + 794 + 822 + 260+ 182+316+208 + 114 + 180+228+188+276+130 + 236 + 196 + 136 + 142 + 274 + 54 + 188 + 166 + 72 + 122 + 40 + 82 + 84 + 74 + 88 + 108 + 52 + 26 + 20 + 64 + 152 + 392 + 116 + 222 + 328 + 138 + 170 + 196 + 34+92 + 56 + 48 + 22 + 190 + 62 + 18 + 140 + 48 + 54 + 212 + 92 + 60 + 122+80 + 126 + 90 + 8 + 84 + 104 + 40 + 58 + 62 + 78 + 20 + 200 + 76 + 32 + 64 + 10 + 62 + 62+2+142+26+16+70+20+34+30\n",
    "float(total_correct)/total_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:01<00:00, 148.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_rst_feats2 = data_formatter.get_rst_data(train_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 128.87it/s]\n"
     ]
    }
   ],
   "source": [
    "test_rst_feats2 = data_formatter.get_rst_data(test_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rst_cat_N-antithesis',\n",
       " 'rst_cat_N-attribution',\n",
       " 'rst_cat_N-circumstance',\n",
       " 'rst_cat_N-comment',\n",
       " 'rst_cat_N-comparison',\n",
       " 'rst_cat_N-concession',\n",
       " 'rst_cat_N-condition',\n",
       " 'rst_cat_N-consequence',\n",
       " 'rst_cat_N-contrast',\n",
       " 'rst_cat_N-definition',\n",
       " 'rst_cat_N-disjunction',\n",
       " 'rst_cat_N-elaboration',\n",
       " 'rst_cat_N-evidence',\n",
       " 'rst_cat_N-example',\n",
       " 'rst_cat_N-explanation',\n",
       " 'rst_cat_N-hypothetical',\n",
       " 'rst_cat_N-list',\n",
       " 'rst_cat_N-manner',\n",
       " 'rst_cat_N-means',\n",
       " 'rst_cat_N-purpose',\n",
       " 'rst_cat_N-question',\n",
       " 'rst_cat_N-reason',\n",
       " 'rst_cat_N-restatement',\n",
       " 'rst_cat_N-result',\n",
       " 'rst_cat_N-same_unit',\n",
       " 'rst_cat_N-sequence',\n",
       " 'rst_cat_N-temporal',\n",
       " 'rst_cat_N-textualorganization',\n",
       " 'rst_cat_N-topic',\n",
       " 'rst_cat_S-antithesis',\n",
       " 'rst_cat_S-attribution',\n",
       " 'rst_cat_S-circumstance',\n",
       " 'rst_cat_S-comment',\n",
       " 'rst_cat_S-comparison',\n",
       " 'rst_cat_S-concession',\n",
       " 'rst_cat_S-condition',\n",
       " 'rst_cat_S-consequence',\n",
       " 'rst_cat_S-definition',\n",
       " 'rst_cat_S-elaboration',\n",
       " 'rst_cat_S-example',\n",
       " 'rst_cat_S-explanation',\n",
       " 'rst_cat_S-hypothetical',\n",
       " 'rst_cat_S-manner',\n",
       " 'rst_cat_S-means',\n",
       " 'rst_cat_S-purpose',\n",
       " 'rst_cat_S-reason',\n",
       " 'rst_cat_S-restatement',\n",
       " 'rst_cat_S-result',\n",
       " 'rst_cat_S-temporal',\n",
       " 'rst_final_count>0',\n",
       " 'rst_final_count>1',\n",
       " 'rst_final_count>2',\n",
       " 'rst_final_count>3',\n",
       " 'rst_final_count>4',\n",
       " 'rst_final_count>5',\n",
       " 'rst_final_count>6',\n",
       " 'rst_final_count>7',\n",
       " 'rst_final_count>8',\n",
       " 'rst_final_count>9']"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.Featurizer(s).get_rst_feature_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
