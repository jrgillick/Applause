{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jrgillick/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/jrgillick/.local/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle, numpy as np, keras, time\n",
    "import attention, attention_with_context\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/jrgillick/x_train.pkl') as f:\n",
    "    X_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/jrgillick/x_test.pkl') as f:\n",
    "    X_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/jrgillick/y_train.pkl') as f:\n",
    "    y_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/data/jrgillick/y_test.pkl') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load in 38.2689790726\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "with open('/data/jrgillick/individual_feature_lists_skip_thoughts.pkl') as f:\n",
    "    individual_feature_lists = pickle.load(f)\n",
    "print \"load in \" + str(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/jrgillick/individual_feature_lists_no_n_grams.pkl','rb') as f:\n",
    "    individual_feature_lists = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['euphony',\n",
       " 'labels',\n",
       " 'word_overlap',\n",
       " 'phone',\n",
       " 'substring',\n",
       " 'liu',\n",
       " 'cosine',\n",
       " 'rst',\n",
       " 'audio',\n",
       " 'id']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_feature_lists[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open('/data/jrgillick/individual_feature_lists_no_n_grams.pkl','wb') as f:\n",
    "#    pickle.dump(individual_feature_lists, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'individual_feature_lists' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fc0e5f92d48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual_feature_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'individual_feature_lists' is not defined"
     ]
    }
   ],
   "source": [
    "len(individual_feature_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speaker_names = ['donald_trump',\n",
    " 'hilary_clinton',\n",
    " 'bernie_sanders',\n",
    " 'ted_cruz',\n",
    " 'marco_rubio',\n",
    " 'john_kasich',\n",
    " 'barack_obama',\n",
    " 'bill_clinton',\n",
    " 'joe_biden',\n",
    " 'mike_pence',\n",
    " 'carly_fiorina',\n",
    " 'jeb_bush',\n",
    " 'rand_paul',\n",
    " 'gary_johnson',\n",
    " 'chris_christie',\n",
    " 'rick_santorum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(X_train, X_test):\n",
    "    new_X_train = np.copy(X_train)\n",
    "    new_X_test = np.copy(X_test)\n",
    "    for i in xrange(new_X_train.shape[1]):\n",
    "        if set(new_X_train[:,i]) != set([0,1]) and set(new_X_train[:,i]) != set([0]) and set(new_X_train[:,i]) != set([1]):\n",
    "            #print 'norming'\n",
    "            #print set(new_X_train[:,i])\n",
    "            mean = np.mean(new_X_train[:,i])\n",
    "            new_X_train[:,i] -= mean\n",
    "            new_X_test[:,i] -=mean\n",
    "            std = np.std(X_train[:,i])\n",
    "            if std > 1e-2:\n",
    "                new_X_train[:,i] /= std\n",
    "                new_X_test[:,i] /= std\n",
    "    return new_X_train, new_X_test\n",
    "\n",
    "def get_train_and_test_sets(speaker_name):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for i in range(len(individual_feature_lists)):\n",
    "        if speaker_name in individual_feature_lists[i]['id']:\n",
    "            test_set.append(individual_feature_lists[i])\n",
    "        else:\n",
    "            train_set.append(individual_feature_lists[i])\n",
    "    return train_set, test_set\n",
    "\n",
    "def get_features(data_set, feature_names):\n",
    "    all_feats = []\n",
    "    for i in range(len(data_set)):\n",
    "        feats = [data_set[i][name] for name in feature_names]\n",
    "        all_feats.append(np.hstack(feats))\n",
    "    return all_feats\n",
    "\n",
    "def get_labels(data_set):\n",
    "    all_labels = []\n",
    "    for i in range(len(data_set)):\n",
    "        all_labels.append(data_set[i]['labels'])\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import *\n",
    "def initialize_lstm_attention_model(input_dim, layer_sizes, dropout = 0.5, loss = 'binary_crossentropy', metrics = ['accuracy'], batch_norm = True, bidirectional = False):\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.1,input_shape=(None, input_dim)))\n",
    "    for i in range(len(layer_sizes)):\n",
    "        return_sequences = False if i == len(layer_sizes) - 1 else True\n",
    "        if bidirectional:\n",
    "            model.add(Bidirectional(LSTM(layer_sizes[i], return_sequences=return_sequences, dropout=dropout),input_shape=(None, input_dim)))\n",
    "        else:\n",
    "            model.add(LSTM(layer_sizes[i],input_shape=(None,input_dim),return_sequences=True,dropout=dropout))\n",
    "        if batch_norm: model.add(keras.layers.BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "    #model.add(Dense(10))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    model.add(attention_with_context.AttentionWithContext())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer,loss=loss,metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_neural_single_speaker(feature_set, phrase_count, verbose=True):\n",
    "    all_true = []; all_pred = []\n",
    "    C = None\n",
    "    for speaker in speaker_names:\n",
    "        speaker_true = []; speaker_pred = []\n",
    "        print speaker + \": \"\n",
    "        other, speaker_data = get_train_and_test_sets(speaker)\n",
    "        speaker_data = np.array(speaker_data)\n",
    "        #speaker_labels = get_labels(speaker_data)\n",
    "        \n",
    "        if len(speaker_data) == 1:\n",
    "            continue\n",
    "        \n",
    "        if len(speaker_data) > 10:\n",
    "            kf = KFold(n_splits=10)\n",
    "        else:\n",
    "            kf = KFold(n_splits=len(speaker_data))\n",
    "            \n",
    "        for train_index, test_index in kf.split(speaker_data):\n",
    "            train_set = speaker_data[train_index]\n",
    "            test_set = speaker_data[test_index]\n",
    "            #train_set, test_set = train_test_split(speaker_data, test_size=0.2, random_state=43)\n",
    "\n",
    "            labels_train = get_labels(train_set)\n",
    "            data_train = get_features(train_set,feature_set)\n",
    "\n",
    "            labels_test = get_labels(test_set)\n",
    "            data_test = get_features(test_set,feature_set)\n",
    "\n",
    "            current_train_formatted_feats, current_train_formatted_labs = models.format_balanced_multiple_phrase_input(data_train,labels_train,phrase_count=phrase_count)\n",
    "            current_test_formatted_feats, current_test_formatted_labs = models.format_balanced_multiple_phrase_input(data_test,labels_test,phrase_count=phrase_count)\n",
    "\n",
    "            X_train = np.array(current_train_formatted_feats).astype('float64')\n",
    "            y_train = np.array(current_train_formatted_labs)\n",
    "\n",
    "            X_test = np.array(current_test_formatted_feats).astype('float64')\n",
    "            y_test = np.array(current_test_formatted_labs)\n",
    "\n",
    "            X_train, X_test = normalize_data(X_train,X_test)\n",
    "            #print X_train.shape\n",
    "            #print X_test.shape\n",
    "            \n",
    "            if len(y_train) > 0 and len(y_test) > 0:\n",
    "                lstm_model = initialize_lstm_attention_model(X_train.shape[1]/phrase_count,[25],bidirectional=False,dropout=0.6,batch_norm=True) \n",
    "                lstm_model.fit(X_train.reshape(X_train.shape[0],phrase_count,-1),np.array(y_train),batch_size=512,epochs=15,shuffle=True,verbose=False)\n",
    "\n",
    "                y_true, y_pred = models.evaluate_model(lstm_model, X_test.reshape(X_test.shape[0],phrase_count,-1), y_test, model_type='keras')\n",
    "\n",
    "                all_true += list(y_true)\n",
    "                all_pred += list(y_pred)\n",
    "                \n",
    "\n",
    "            print\n",
    "    return all_true, all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_neural_cross_validation(feature_set, phrase_count):\n",
    "    all_true = []; all_pred = []\n",
    "    num_iters = None\n",
    "    for speaker in speaker_names:\n",
    "        print speaker + \": \"\n",
    "        train_set, test_set = get_train_and_test_sets(speaker)\n",
    "\n",
    "        labels_train = get_labels(train_set)\n",
    "        data_train = get_features(train_set,feature_set)\n",
    "\n",
    "        labels_test = get_labels(test_set)\n",
    "        data_test = get_features(test_set,feature_set)\n",
    "\n",
    "        current_train_formatted_feats, current_train_formatted_labs = models.format_balanced_multiple_phrase_input(data_train,labels_train,phrase_count=phrase_count)\n",
    "        current_test_formatted_feats, current_test_formatted_labs = models.format_balanced_multiple_phrase_input(data_test,labels_test,phrase_count=phrase_count)\n",
    "\n",
    "        X_train = np.array(current_train_formatted_feats).astype('float64')\n",
    "        y_train = np.array(current_train_formatted_labs)\n",
    "        \n",
    "        print X_train.shape\n",
    "\n",
    "        X_test = np.array(current_test_formatted_feats).astype('float64')\n",
    "        y_test = np.array(current_test_formatted_labs)\n",
    "\n",
    "        X_train, X_test = normalize_data(X_train,X_test)\n",
    "        \n",
    "        lstm_model = initialize_lstm_attention_model(X_train.shape[1]/phrase_count,[100],bidirectional=False,dropout=0.5,batch_norm=True) \n",
    "        lstm_model.fit(X_train.reshape(X_train.shape[0],phrase_count,-1),np.array(y_train),batch_size=1024,epochs=25,shuffle=True,verbose=False)\n",
    "        \n",
    "        #if num_iters is None:\n",
    "        #    \n",
    "        #    model = models.train_cv_logistic_regression_faster(X_train,y_train)\n",
    "        #    C = model.best_params_['C']\n",
    "        \n",
    "        #lstm_model.fit(X_train.reshape(X_train.shape[0],5,-1),np.array(y_train),batch_size=512,epochs=15,shuffle=True)\n",
    "        y_true, y_pred = models.evaluate_model(lstm_model, X_test.reshape(X_test.shape[0],phrase_count,-1), y_test, model_type='keras')\n",
    "        \n",
    "        all_true += list(y_true)\n",
    "        all_pred += list(y_pred)\n",
    "        print\n",
    "    return all_true, all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_true, all_pred = run_neural_single_speaker(['audio','liu','euphony','phone','cosine','substring','word_overlap','rst'],phrase_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625 +/- 0.005 (21930/35092) | Precision: 0.628 | Recall: 0.613 | F1: 0.621\n"
     ]
    }
   ],
   "source": [
    "print_results(total_true, total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald_trump: \n",
      "(22376, 270)\n",
      "Accuracy: 0.597 +/- 0.009 (7588/12716) | Precision: 0.621 | Recall: 0.497 | F1: 0.552\n",
      "\n",
      "hilary_clinton: \n",
      "(27942, 270)\n",
      "Accuracy: 0.650 +/- 0.011 (4647/7150) | Precision: 0.627 | Recall: 0.741 | F1: 0.679\n",
      "\n",
      "bernie_sanders: \n",
      "(28630, 270)\n",
      "Accuracy: 0.595 +/- 0.012 (3844/6462) | Precision: 0.635 | Recall: 0.445 | F1: 0.524\n",
      "\n",
      "ted_cruz: \n",
      "(33040, 270)\n",
      "Accuracy: 0.600 +/- 0.021 (1231/2052) | Precision: 0.685 | Recall: 0.369 | F1: 0.480\n",
      "\n",
      "marco_rubio: \n",
      "(33530, 270)\n",
      "Accuracy: 0.649 +/- 0.024 (1013/1562) | Precision: 0.675 | Recall: 0.572 | F1: 0.620\n",
      "\n",
      "john_kasich: \n",
      "(34476, 270)\n",
      "Accuracy: 0.661 +/- 0.037 (407/616) | Precision: 0.677 | Recall: 0.614 | F1: 0.644\n",
      "\n",
      "barack_obama: \n",
      "(33266, 270)\n",
      "Accuracy: 0.629 +/- 0.022 (1149/1826) | Precision: 0.685 | Recall: 0.479 | F1: 0.564\n",
      "\n",
      "bill_clinton: \n",
      "(34518, 270)\n",
      "Accuracy: 0.666 +/- 0.039 (382/574) | Precision: 0.675 | Recall: 0.638 | F1: 0.656\n",
      "\n",
      "joe_biden: \n",
      "(34564, 270)\n",
      "Accuracy: 0.680 +/- 0.040 (359/528) | Precision: 0.686 | Recall: 0.663 | F1: 0.674\n",
      "\n",
      "mike_pence: \n",
      "(34606, 270)\n",
      "Accuracy: 0.669 +/- 0.042 (325/486) | Precision: 0.693 | Recall: 0.605 | F1: 0.646\n",
      "\n",
      "carly_fiorina: \n",
      "(34840, 270)\n",
      "Accuracy: 0.631 +/- 0.060 (159/252) | Precision: 0.622 | Recall: 0.667 | F1: 0.644\n",
      "\n",
      "jeb_bush: \n",
      "(34714, 270)\n",
      "Accuracy: 0.656 +/- 0.048 (248/378) | Precision: 0.679 | Recall: 0.593 | F1: 0.633\n",
      "\n",
      "rand_paul: \n",
      "(34824, 270)\n",
      "Accuracy: 0.653 +/- 0.057 (175/268) | Precision: 0.621 | Recall: 0.784 | F1: 0.693\n",
      "\n",
      "gary_johnson: \n",
      "(34984, 270)\n",
      "Accuracy: 0.593 +/- 0.093 (64/108) | Precision: 0.586 | Recall: 0.630 | F1: 0.607\n",
      "\n",
      "chris_christie: \n",
      "(35012, 270)\n",
      "Accuracy: 0.575 +/- 0.108 (46/80) | Precision: 0.615 | Recall: 0.400 | F1: 0.485\n",
      "\n",
      "rick_santorum: \n",
      "(35058, 270)\n",
      "Accuracy: 0.471 +/- 0.168 (16/34) | Precision: 0.474 | Recall: 0.529 | F1: 0.500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_true, total_pred = run_neural_cross_validation(['audio','liu','euphony'],phrase_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(total_true, total_pred):\n",
    "    total_correct = np.sum(np.array(total_true) == np.array(total_pred))\n",
    "    acc=float(total_correct) / len(total_true)\n",
    "    std=math.sqrt( (acc * (1-acc)) / len(total_true) )\n",
    "    precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(total_true, total_pred)]\n",
    "    #print \"Accuracy: %.3f +/- %.3f (%s/%s)\" % (acc, 1.96*std, total_correct, len(total_true))\n",
    "    print \"Accuracy: %.3f +/- %.3f (%s/%s) | Precision: %.3f | Recall: %.3f | F1: %.3f\" % (acc, 1.96*std, total_correct, len(total_true), precision, recall, f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald_trump: \n",
      "(22678, 186)\n",
      "12608/12846 [============================>.] - ETA: 0sAccuracy: 0.599 +/- 0.008 (7696/12846) | Precision: 0.600 | Recall: 0.594 | F1: 0.597\n",
      "\n",
      "hilary_clinton: \n",
      "(28264, 186)\n",
      "6880/7260 [===========================>..] - ETA: 0sAccuracy: 0.649 +/- 0.011 (4713/7260) | Precision: 0.624 | Recall: 0.751 | F1: 0.682\n",
      "\n",
      "bernie_sanders: \n",
      "(29006, 186)\n",
      "6368/6518 [============================>.] - ETA: 0sAccuracy: 0.627 +/- 0.012 (4085/6518) | Precision: 0.629 | Recall: 0.619 | F1: 0.624\n",
      "\n",
      "ted_cruz: \n",
      "(33442, 186)\n",
      "2080/2082 [============================>.] - ETA: 0sAccuracy: 0.599 +/- 0.021 (1247/2082) | Precision: 0.635 | Recall: 0.466 | F1: 0.537\n",
      "\n",
      "marco_rubio: \n",
      "(33938, 186)\n",
      "1248/1586 [======================>.......] - ETA: 0sAccuracy: 0.651 +/- 0.023 (1033/1586) | Precision: 0.661 | Recall: 0.622 | F1: 0.641\n",
      "\n",
      "john_kasich: \n",
      "(34886, 186)\n",
      "416/638 [==================>...........] - ETA: 1s Accuracy: 0.676 +/- 0.036 (431/638) | Precision: 0.676 | Recall: 0.674 | F1: 0.675\n",
      "\n",
      "barack_obama: \n",
      "(33684, 186)\n",
      "1632/1840 [=========================>....] - ETA: 0sAccuracy: 0.622 +/- 0.022 (1144/1840) | Precision: 0.631 | Recall: 0.585 | F1: 0.607\n",
      "\n",
      "bill_clinton: \n",
      "(34940, 186)\n",
      "480/584 [=======================>......] - ETA: 0s Accuracy: 0.639 +/- 0.039 (373/584) | Precision: 0.642 | Recall: 0.627 | F1: 0.634\n",
      "\n",
      "joe_biden: \n",
      "(34984, 186)\n",
      "448/540 [=======================>......] - ETA: 0s Accuracy: 0.652 +/- 0.040 (352/540) | Precision: 0.643 | Recall: 0.681 | F1: 0.662\n",
      "\n",
      "mike_pence: \n",
      "(35032, 186)\n",
      "416/492 [========================>.....] - ETA: 0s Accuracy: 0.679 +/- 0.041 (334/492) | Precision: 0.663 | Recall: 0.728 | F1: 0.694\n",
      "\n",
      "carly_fiorina: \n",
      "(35266, 186)\n",
      " 32/258 [==>...........................] - ETA: 26sAccuracy: 0.574 +/- 0.060 (148/258) | Precision: 0.558 | Recall: 0.705 | F1: 0.623\n",
      "\n",
      "jeb_bush: \n",
      "(35142, 186)\n",
      " 32/382 [=>............................] - ETA: 41sAccuracy: 0.688 +/- 0.046 (263/382) | Precision: 0.705 | Recall: 0.649 | F1: 0.676\n",
      "\n",
      "rand_paul: \n",
      "(35256, 186)\n",
      " 32/268 [==>...........................] - ETA: 27sAccuracy: 0.638 +/- 0.058 (171/268) | Precision: 0.607 | Recall: 0.784 | F1: 0.684\n",
      "\n",
      "gary_johnson: \n",
      "(35412, 186)\n",
      " 32/112 [=======>......................] - ETA: 9sAccuracy: 0.625 +/- 0.090 (70/112) | Precision: 0.630 | Recall: 0.607 | F1: 0.618\n",
      "\n",
      "chris_christie: \n",
      "(35440, 186)\n",
      "32/84 [==========>...................] - ETA: 6sAccuracy: 0.738 +/- 0.094 (62/84) | Precision: 0.778 | Recall: 0.667 | F1: 0.718\n",
      "\n",
      "rick_santorum: \n",
      "(35490, 186)\n",
      "32/34 [===========================>..] - ETA: 0sAccuracy: 0.588 +/- 0.165 (20/34) | Precision: 0.615 | Recall: 0.471 | F1: 0.533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_true, all_pred = run_neural_cross_validation(['audio','liu','euphony','phone'],phrase_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.623 +/- 0.005 (22142/35524) | Precision: 0.621 | Recall: 0.632 | F1: 0.627\n"
     ]
    }
   ],
   "source": [
    "total_correct = np.sum(np.array(all_true) == np.array(all_pred))\n",
    "acc=float(total_correct) / len(all_true)\n",
    "std=math.sqrt( (acc * (1-acc)) / len(all_true) )\n",
    "precision, recall, f1, support = [l[1] for l in precision_recall_fscore_support(all_true, all_pred)]\n",
    "print \"Accuracy: %.3f +/- %.3f (%s/%s) | Precision: %.3f | Recall: %.3f | F1: %.3f\" % (acc, 1.96*std, total_correct, len(all_true), precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/jrgillick/x_train_deltas.pkl','rb') as f:\n",
    "    X_train_deltas = pickle.load(f)\n",
    "    \n",
    "with open('/data/jrgillick/x_test_deltas.pkl','rb') as f:\n",
    "    X_test_deltas = pickle.load(f)\n",
    "\n",
    "with open('/data/jrgillick/y_train_deltas.pkl','rb') as f:\n",
    "    y_train_deltas = pickle.load(f)\n",
    "    \n",
    "with open('/data/jrgillick/y_test_deltas.pkl','rb') as f:\n",
    "    y_test_deltas = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/jrgillick/x_train_rst.pkl','rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "    \n",
    "with open('/data/jrgillick/x_test_rst.pkl','rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open('/data/jrgillick/y_train_rst.pkl','rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "    \n",
    "with open('/data/jrgillick/y_test_rst.pkl','rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_data(X_train, X_test):\n",
    "    new_X_train = np.copy(X_train)\n",
    "    new_X_test = np.copy(X_test)\n",
    "    for i in xrange(new_X_train.shape[1]):\n",
    "        if set(new_X_train[:,i]) != set([0,1]):\n",
    "            mean = np.mean(new_X_train[:,i])\n",
    "            new_X_train[:,i] -= mean\n",
    "            new_X_test[:,i] -=mean\n",
    "            std = np.std(X_train[:,i])\n",
    "            new_X_train[:,i] /= std\n",
    "            new_X_test[:,i] /= std\n",
    "    return new_X_train, new_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16932148,  0.36295728,  0.75744165,  0.62218308],\n",
       "       [ 0.01858241,  0.3735383 ,  0.36718772,  0.1485428 ],\n",
       "       [ 0.0574262 ,  0.64471333,  0.6655188 ,  0.2945661 ]])"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_X = np.random.uniform(0,1,(3,4))\n",
    "t_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16932148,  0.        ,  0.        ,  0.62218308],\n",
       "       [ 0.01858241,  0.        ,  0.36718772,  0.1485428 ],\n",
       "       [ 0.0574262 ,  1.        ,  0.6655188 ,  0.2945661 ]])"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_X[0,1] = t_X[1,1] = 0\n",
    "t_X[2,1] = 1\n",
    "t_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36997627,  0.        , -1.26472911,  1.34862213],\n",
       "       [-0.98891867,  0.        ,  0.08432696, -1.0429759 ],\n",
       "       [-0.3810576 ,  1.        ,  1.18040215, -0.30564623]])"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_data(t_X,t_X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16932148,  0.        ,  0.        ,  0.62218308],\n",
       "       [ 0.01858241,  0.        ,  0.36718772,  0.1485428 ],\n",
       "       [ 0.0574262 ,  1.        ,  0.6655188 ,  0.2945661 ]])"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28132, 1550)"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_train[:,-17]) == set([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff_model = models.initialize_feed_forward_model(input_dim=1550,layer_sizes=[50],dropout=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "28132/28132 [==============================] - 0s - loss: 0.5613 - acc: 0.7108     \n",
      "Epoch 2/3\n",
      "28132/28132 [==============================] - 0s - loss: 0.5644 - acc: 0.7065     \n",
      "Epoch 3/3\n",
      "28132/28132 [==============================] - 0s - loss: 0.5632 - acc: 0.7090     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c37a07fd0>"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_model.fit(X_train,np.array(y_train),batch_size=512,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/6514 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.65558727452972387, 0.61728584543122156]"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_model.evaluate(X_test,np.array(y_test),batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6496/6606 [============================>.] - ETA: 0sAccuracy: 0.639 +/- 0.012 (4221/6606) | Precision: 0.635 | Recall: 0.652 | F1: 0.644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6389645776566758,\n",
       " 0.63531839622641506,\n",
       " 0.65243717832273695,\n",
       " 0.64376400298730396)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.evaluate_model(ff_model, X_test, y_test,model_type='keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28486, 930)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310.0"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "930/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.train_cv_logistic_regression(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.546 +/- 0.012 (3654/6692) | Precision: 0.562 | Recall: 0.420 | F1: 0.481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5460251046025104,\n",
       " 0.561550759392486,\n",
       " 0.41990436341900778,\n",
       " 0.48050615595075236)"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just RST at t0\n",
    "models.evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_continuous_rst_resolution_val(X):\n",
    "    last_cols = X[:,-10:]\n",
    "    output_vals = []\n",
    "    for i in range(len(last_cols)):\n",
    "        if len(last_cols[i].nonzero()[0]) == 0:\n",
    "            output_vals.append(0)\n",
    "        else:\n",
    "            output_vals.append(last_cols[i].nonzero()[0].argmax())\n",
    "    return np.array(output_vals).reshape((-1,1))\n",
    "\n",
    "def convert_rst_to_continuous(X):\n",
    "    first_cols = X[:,0:-10]\n",
    "    last_cols = get_continuous_rst_resolution_val(X)\n",
    "    return np.hstack([first_cols,last_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train = convert_rst_to_continuous(X_train)\n",
    "#X_test = convert_rst_to_continuous(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6692, 50)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28832, 1)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(continuous_vals).reshape((-1,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.631 +/- 0.012 (4169/6606) | Precision: 0.632 | Recall: 0.629 | F1: 0.630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6310929458068423,\n",
       " 0.63177115033475351,\n",
       " 0.62851952770208896,\n",
       " 0.63014114433146151)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all feats with deltas, 3 phrases\n",
    "models.evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.631 +/- 0.012 (4169/6606) | Precision: 0.632 | Recall: 0.629 | F1: 0.630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6310929458068423,\n",
       " 0.63177115033475351,\n",
       " 0.62851952770208896,\n",
       " 0.63014114433146151)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('all_feature_names.pkl','rb') as f:\n",
    "    all_feature_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_feature_names = ['rst_cat_N-antithesis',\n",
    " 'rst_cat_N-attribution',\n",
    " 'rst_cat_N-circumstance',\n",
    " 'rst_cat_N-comment',\n",
    " 'rst_cat_N-comparison',\n",
    " 'rst_cat_N-concession',\n",
    " 'rst_cat_N-condition',\n",
    " 'rst_cat_N-consequence',\n",
    " 'rst_cat_N-contrast',\n",
    " 'rst_cat_N-definition',\n",
    " 'rst_cat_N-disjunction',\n",
    " 'rst_cat_N-elaboration',\n",
    " 'rst_cat_N-evidence',\n",
    " 'rst_cat_N-example',\n",
    " 'rst_cat_N-explanation',\n",
    " 'rst_cat_N-hypothetical',\n",
    " 'rst_cat_N-list',\n",
    " 'rst_cat_N-manner',\n",
    " 'rst_cat_N-means',\n",
    " 'rst_cat_N-purpose',\n",
    " 'rst_cat_N-question',\n",
    " 'rst_cat_N-reason',\n",
    " 'rst_cat_N-restatement',\n",
    " 'rst_cat_N-result',\n",
    " 'rst_cat_N-same_unit',\n",
    " 'rst_cat_N-sequence',\n",
    " 'rst_cat_N-temporal',\n",
    " 'rst_cat_N-textualorganization',\n",
    " 'rst_cat_N-topic',\n",
    " 'rst_cat_S-antithesis',\n",
    " 'rst_cat_S-attribution',\n",
    " 'rst_cat_S-circumstance',\n",
    " 'rst_cat_S-comment',\n",
    " 'rst_cat_S-comparison',\n",
    " 'rst_cat_S-concession',\n",
    " 'rst_cat_S-condition',\n",
    " 'rst_cat_S-consequence',\n",
    " 'rst_cat_S-definition',\n",
    " 'rst_cat_S-elaboration',\n",
    " 'rst_cat_S-example',\n",
    " 'rst_cat_S-explanation',\n",
    " 'rst_cat_S-hypothetical',\n",
    " 'rst_cat_S-manner',\n",
    " 'rst_cat_S-means',\n",
    " 'rst_cat_S-purpose',\n",
    " 'rst_cat_S-reason',\n",
    " 'rst_cat_S-restatement',\n",
    " 'rst_cat_S-result',\n",
    " 'rst_cat_S-temporal',\n",
    " 'rst_final_count>0',\n",
    " 'rst_final_count>1',\n",
    " 'rst_final_count>2',\n",
    " 'rst_final_count>3',\n",
    " 'rst_final_count>4',\n",
    " 'rst_final_count>5',\n",
    " 'rst_final_count>6',\n",
    " 'rst_final_count>7',\n",
    " 'rst_final_count>8',\n",
    " 'rst_final_count>9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefs = model.best_estimator_.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rst_cat_S-reason', -0.080807832271602112),\n",
       " ('rst_cat_N-reason', -0.073367700923741674),\n",
       " ('rst_cat_N-temporal', -0.060824950389316561),\n",
       " ('rst_cat_N-sequence', -0.032930750757426797),\n",
       " ('rst_cat_N-attribution', -0.029187086181217851),\n",
       " ('rst_final_count>5', -0.020056612614410618),\n",
       " ('rst_final_count>1', -0.019377843396127557),\n",
       " ('rst_cat_N-concession', -0.01894895793585763),\n",
       " ('rst_cat_S-antithesis', -0.012867169157696324),\n",
       " ('rst_cat_S-circumstance', -0.0091779903554919471),\n",
       " ('rst_final_count>6', -0.0086567385876791109),\n",
       " ('rst_cat_S-concession', -0.0068395373167089981),\n",
       " ('rst_cat_N-result', -0.0045257759789439434),\n",
       " ('rst_cat_S-result', -0.0045257759789439434),\n",
       " ('rst_cat_N-restatement', 0.0),\n",
       " ('rst_cat_S-definition', 0.0),\n",
       " ('rst_cat_S-restatement', 0.0),\n",
       " ('rst_cat_N-question', 0.0),\n",
       " ('rst_cat_N-hypothetical', 0.0),\n",
       " ('rst_cat_N-definition', 0.0),\n",
       " ('rst_cat_N-evidence', 0.0),\n",
       " ('rst_cat_S-hypothetical', 0.0),\n",
       " ('rst_final_count>7', 0.0019309184466439378),\n",
       " ('rst_cat_S-means', 0.0028816894086139042),\n",
       " ('rst_cat_S-explanation', 0.003819771561079122),\n",
       " ('rst_cat_N-topic', 0.0039723470017845163),\n",
       " ('rst_cat_N-contrast', 0.0039794285096365579),\n",
       " ('rst_cat_S-comment', 0.0053868873415859348),\n",
       " ('rst_cat_N-consequence', 0.0064304066628869403),\n",
       " ('rst_cat_S-elaboration', 0.0097413896910873658),\n",
       " ('rst_cat_N-disjunction', 0.0099782474726517051),\n",
       " ('rst_cat_N-comment', 0.010153750312276786),\n",
       " ('rst_cat_S-condition', 0.012622027586703066),\n",
       " ('rst_cat_N-same_unit', 0.012838237520146423),\n",
       " ('rst_cat_S-example', 0.01284750269881099),\n",
       " ('rst_cat_S-consequence', 0.015291656449221577),\n",
       " ('rst_cat_S-attribution', 0.015590119567381563),\n",
       " ('rst_final_count>8', 0.016837573093869445),\n",
       " ('rst_cat_N-example', 0.025346631055671885),\n",
       " ('rst_cat_S-temporal', 0.026498138872329911),\n",
       " ('rst_cat_N-explanation', 0.026953669380404752),\n",
       " ('rst_cat_S-manner', 0.030280391868448713),\n",
       " ('rst_final_count>9', 0.030512104742522774),\n",
       " ('rst_cat_N-antithesis', 0.034903437849691007),\n",
       " ('rst_final_count>0', 0.036252546163673016),\n",
       " ('rst_cat_N-manner', 0.049121579938088224),\n",
       " ('rst_cat_S-comparison', 0.052500326322483998),\n",
       " ('rst_final_count>2', 0.054700741452366738),\n",
       " ('rst_cat_N-means', 0.060456099332505057),\n",
       " ('rst_final_count>4', 0.061978314653249635),\n",
       " ('rst_cat_S-purpose', 0.072069559149651005),\n",
       " ('rst_cat_N-textualorganization', 0.088133176643425543),\n",
       " ('rst_cat_N-circumstance', 0.10024178729979119),\n",
       " ('rst_cat_N-condition', 0.10424632889632782),\n",
       " ('rst_final_count>3', 0.10655180256422206),\n",
       " ('rst_cat_N-comparison', 0.15278824005417552),\n",
       " ('rst_cat_N-elaboration', 0.17714808207114854),\n",
       " ('rst_cat_N-list', 0.18976086048413057),\n",
       " ('rst_cat_N-purpose', 0.29073113066821071)]"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(np.array(all_feature_names)[np.argsort(coefs)],coefs[np.argsort(coefs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001}"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.665 +/- 0.011 (4929/7416) | Precision: 0.680 | Recall: 0.622 | F1: 0.650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6646440129449838,\n",
       " 0.67982326951399119,\n",
       " 0.62243797195253503,\n",
       " 0.64986625369562157)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_lstm_attention_model(input_dim, layer_sizes, dropout = 0.5, loss = 'binary_crossentropy', metrics = ['accuracy'], batch_norm = True, bidirectional = False):\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.1,input_shape=(None, input_dim)))\n",
    "    for i in range(len(layer_sizes)):\n",
    "        return_sequences = False if i == len(layer_sizes) - 1 else True\n",
    "        if bidirectional:\n",
    "            model.add(Bidirectional(LSTM(layer_sizes[i], return_sequences=return_sequences, dropout=dropout),input_shape=(None, input_dim)))\n",
    "        else:\n",
    "            model.add(LSTM(layer_sizes[i],input_shape=(None,input_dim),return_sequences=True,dropout=dropout))\n",
    "        if batch_norm: model.add(keras.layers.BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "    #model.add(Dense(10))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    model.add(attention_with_context.AttentionWithContext())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer,loss=loss,metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lstm_model = models.initialize_lstm_model(310,[80],bidirectional=False,dropout=0.6,batch_norm=True)\n",
    "lstm_model = initialize_lstm_attention_model(310,[80,40],bidirectional=False,dropout=0.6,batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'attention_with_context' from 'attention_with_context.pyc'>"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(attention)\n",
    "reload(attention_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94426, 164)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,0:164].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "28132/28132 [==============================] - 2s - loss: 0.6238 - acc: 0.6503     \n",
      "Epoch 2/3\n",
      "28132/28132 [==============================] - 2s - loss: 0.6185 - acc: 0.6586     \n",
      "Epoch 3/3\n",
      "28132/28132 [==============================] - 2s - loss: 0.6193 - acc: 0.6573     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c331fa2d0>"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(X_train.reshape(X_train.shape[0],5,-1),np.array(y_train),batch_size=512,epochs=3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6514/6514 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.63343355565631831, 0.64138778294746879]"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.evaluate(X_test.reshape(X_test.shape[0],5,-1),np.array(y_test),batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6496/6606 [============================>.] - ETA: 0sAccuracy: 0.633 +/- 0.012 (4181/6606) | Precision: 0.637 | Recall: 0.618 | F1: 0.627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.632909476233727,\n",
       " 0.63693075483468498,\n",
       " 0.61822585528307594,\n",
       " 0.62743893071132273)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.evaluate_model(lstm_model,X_test.reshape(X_test.shape[0],3,-1),np.array(y_test),model_type='keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7456/7727 [===========================>..] - ETA: 0sAccuracy: 0.639 +/- 0.011 (4938/7727) | Precision: 0.638 | Recall: 0.637 | F1: 0.637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6390578491005565,\n",
       " 0.63787721123829344,\n",
       " 0.63704858404780462,\n",
       " 0.63746262836344736)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.evaluate_model(model,scaler.transform(X_test),y_test,model_type='keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7456/7633 [============================>.] - ETA: 0sAccuracy: 0.618 +/- 0.011 (4720/7633) | Precision: 0.641 | Recall: 0.555 | F1: 0.595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6183676143063016,\n",
       " 0.64088729016786572,\n",
       " 0.55489229172073706,\n",
       " 0.59479760745583521)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.evaluate_model(lstm_model,lstm_x_test,lstm_y_test,model_type='keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
